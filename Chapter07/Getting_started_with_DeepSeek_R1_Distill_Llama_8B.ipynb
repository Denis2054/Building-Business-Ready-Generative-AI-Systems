{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "toc_visible": true,
      "authorship_tag": "ABX9TyMj02DYCLeW29VXMWOuot2f"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "751185796314473f9087cacb971c0933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1294c2b9211f4c8a8871ed0228cb82dd",
              "IPY_MODEL_691ff290898249b28dd9dd251b0c3691",
              "IPY_MODEL_c43241ee018d426aa8eb5177676664c8"
            ],
            "layout": "IPY_MODEL_9e160081fa00479c9b4a49fd706f2d71"
          }
        },
        "1294c2b9211f4c8a8871ed0228cb82dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8698950f901495189757a0285ca4f6a",
            "placeholder": "​",
            "style": "IPY_MODEL_47d4f1c1740941959a30b2d7f38a50f5",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "691ff290898249b28dd9dd251b0c3691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f6a4d6f8d854c75baafe041d2da72da",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f779a1a590414dd2afb28474449af582",
            "value": 4
          }
        },
        "c43241ee018d426aa8eb5177676664c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eb0e7ca7ce84e73b3dd9cdb0f6c8a06",
            "placeholder": "​",
            "style": "IPY_MODEL_9f1bd40c562040a8b9fe1d4d1905a794",
            "value": " 4/4 [00:13&lt;00:00,  3.04s/it]"
          }
        },
        "9e160081fa00479c9b4a49fd706f2d71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8698950f901495189757a0285ca4f6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47d4f1c1740941959a30b2d7f38a50f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f6a4d6f8d854c75baafe041d2da72da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f779a1a590414dd2afb28474449af582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4eb0e7ca7ce84e73b3dd9cdb0f6c8a06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f1bd40c562040a8b9fe1d4d1905a794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **🚀 Getting Started with DeepSeek-R1-Distill-Llama-8B**  \n",
        "📌 **Copyright 2025, Denis Rothman**  \n",
        "\n",
        "---\n",
        "\n",
        "## **🚀 Installing and running DeepSeek-R1-Distill-Llama-8B**  \n",
        "\n",
        "This notebook provides a **step-by-step guide** on how to **download and run DeepSeek-R1-Distill-Llama-8B** locally in **Google Drive**.  The version downloaded is an open-source distilled version of DeepSeek-R1 provided by  unsloth, an LLM accelerator,  on Hugging Face :https://unsloth.ai/\n",
        "\n",
        "If you don't want to use Google Drive, you can install the artefacts on a local machine, server or cloud server.\n",
        "\n",
        "### **🔹 How to Get Started**  \n",
        "1️⃣ **Install the model's artifacts** → Set `install_deepseek=True` and run all cells.  \n",
        "2️⃣ **Restart the session** → Disconnect and start a new session.  \n",
        "3️⃣ **Re-run the model** → Set `install_deepseek=False` and run all cells again.  \n",
        "4️⃣ **Interact with the model** → Use it in a prompt session!  \n",
        "\n",
        "⚠️ **System Requirements**  \n",
        "✅ **GPU** – Minimum **16GB** VRAM required.  \n",
        "✅ **Google Drive Space** – At least **20GB** free space.  \n",
        "📌 **Educational Use Only** – For production, deploy artifacts on a **local or cloud server**.\n",
        "\n",
        "---\n",
        "\n",
        "## **📖 Table of Contents**  \n",
        "\n",
        "### **1️⃣ Setting Up the DeepSeek Environment (Hugging Face)**  \n",
        "✅ Checking GPU Activation  \n",
        "📂 Mounting Google Drive  \n",
        "⚙️ Installing the Hugging Face Environment  \n",
        "🔄 Ensuring `install_deepseek=True` for First Run  \n",
        "📌 Checking Transformer Version  \n",
        "\n",
        "### **2️⃣ Downloading DeepSeek-R1-Distill-Llama-8B**  \n",
        "📂 Verifying Download Path  \n",
        "\n",
        "### **3️⃣ Running a DeepSeek Session**  \n",
        "🔄 Setting `install_deepseek=False` for Second Run  \n",
        "📌 Model Information  \n",
        "💬 Running an Interactive Prompt Session  \n",
        "\n",
        "---\n",
        "\n",
        "### **💡 Ready to Use DeepSeek?**  \n",
        "Follow the **installation steps**, ensure you have the required **hardware**, and launch your **interactive AI session** 🚀"
      ],
      "metadata": {
        "id": "dB7uI-BJ94pW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Setting up DeepSeek Hugging Face environment"
      ],
      "metadata": {
        "id": "mA0_omNcKCw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set install_deepseek to True to download and install R1 Distill Llama 8B locally\n",
        "# Set install_deepseek to False to run an R1 session\n",
        "install_deepseek=False"
      ],
      "metadata": {
        "id": "81qmq4cJ65_7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking GPU activation"
      ],
      "metadata": {
        "id": "2WX2FRUyvnmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Lnpx8Ywvkqu",
        "outputId": "b9e81eba-7cdf-403b-da3b-b12b3de87ff1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Mar  5 08:11:04 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0             46W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive"
      ],
      "metadata": {
        "id": "87z54INBvyUJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zJAvtheKuudm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f4b223d-109a-459c-f0b5-b8585351275a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the cache directory in your Google Drive\n",
        "cache_dir = '/content/drive/MyDrive/genaisys/HuggingFaceCache'\n",
        "\n",
        "# Set environment variables to direct Hugging Face to use this cache directory\n",
        "os.environ['TRANSFORMERS_CACHE'] = cache_dir\n",
        "#os.environ['HF_DATASETS_CACHE'] = os.path.join(cache_dir, 'datasets')"
      ],
      "metadata": {
        "id": "TzzNqXIRCSxD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation Hugging Face environment\n",
        "\n",
        "Path in this notebook: drive/MyDrive/genaisys/\n"
      ],
      "metadata": {
        "id": "hk_OMj3Xv7H6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip transformers==4.48.3"
      ],
      "metadata": {
        "id": "07XwZO2Bx1sZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9a793bd-3422-4456-e4a4-35837cb087c8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR: unknown command \"transformers==4.48.3\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.DeepSeek download\n",
        "\n"
      ],
      "metadata": {
        "id": "CMDClDdHJ1nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import time\n",
        "if install_deepseek==True:\n",
        "   # Record the start time\n",
        "  start_time = time.time()\n",
        "\n",
        "  model_name = 'unsloth/DeepSeek-R1-Distill-Llama-8B'\n",
        "  # Load the tokenizer and model\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "  model = AutoModelForCausalLM.from_pretrained(model_name, device_map='auto', torch_dtype='auto')\n",
        "\n",
        "    # Record the end time\n",
        "  end_time = time.time()\n",
        "\n",
        "  # Calculate the elapsed time\n",
        "  elapsed_time = end_time - start_time\n",
        "\n",
        "  print(f\"Time taken to load the model: {elapsed_time:.2f} seconds\")"
      ],
      "metadata": {
        "id": "FT1zO4ShzzON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b49839b-3482-49e3-abeb-6667e4652856"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if install_deepseek==True:\n",
        " !ls -R /content/drive/MyDrive/genaisys/HuggingFaceCache"
      ],
      "metadata": {
        "id": "zz0hLeEhJTt8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "472429b8-467f-459b-d928-37e5273de51e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/genaisys/HuggingFaceCache:\n",
            "models--unsloth--DeepSeek-R1-Distill-Llama-8B  version.txt\n",
            "\n",
            "/content/drive/MyDrive/genaisys/HuggingFaceCache/models--unsloth--DeepSeek-R1-Distill-Llama-8B:\n",
            "blobs  refs  snapshots\n",
            "\n",
            "/content/drive/MyDrive/genaisys/HuggingFaceCache/models--unsloth--DeepSeek-R1-Distill-Llama-8B/blobs:\n",
            "03910325923893259d090bfa92baa4088cd46573\n",
            "0ab389d23c02726e56c53379f99a420035974a33\n",
            "0c15378b8bf8af3ceaa5e7a81372996b5080fe2035fd304b491064f95b8625e2\n",
            "0fd8120f1c6acddc268ebc2583058efaf699a771\n",
            "13263c27b6e1c82a791559fc2fe27af0748060180c559220d45b93b5fffe239e\n",
            "21b8ca8f9ab09417c124d32ba5b9a59bcd417c4594e41a48d3e869a8a328a021\n",
            "49d6c171706a9c36a4ba5f358e9ce94c27557fa812da99aa5ef0961fcd35de3f\n",
            "846e0e5df0c5f053a21f9390ceec3eabc52d06b3\n",
            "afcf8b83f782748e77f548ee46a21ced225f3431\n",
            "d91915040cfac999d8c55f4b5bc6e67367c065e3a7a4e4b9438ce1f256addd86\n",
            "\n",
            "/content/drive/MyDrive/genaisys/HuggingFaceCache/models--unsloth--DeepSeek-R1-Distill-Llama-8B/refs:\n",
            "main\n",
            "\n",
            "/content/drive/MyDrive/genaisys/HuggingFaceCache/models--unsloth--DeepSeek-R1-Distill-Llama-8B/snapshots:\n",
            "71f34f954141d22ccdad72a2e3927dddf702c9de\n",
            "\n",
            "/content/drive/MyDrive/genaisys/HuggingFaceCache/models--unsloth--DeepSeek-R1-Distill-Llama-8B/snapshots/71f34f954141d22ccdad72a2e3927dddf702c9de:\n",
            "config.json\t\t\t  model-00003-of-00004.safetensors  tokenizer_config.json\n",
            "generation_config.json\t\t  model-00004-of-00004.safetensors  tokenizer.json\n",
            "model-00001-of-00004.safetensors  model.safetensors.index.json\n",
            "model-00002-of-00004.safetensors  special_tokens_map.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.DeepSeek-R1-Distill-Llama-8B session"
      ],
      "metadata": {
        "id": "mPFjy90U2gcB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the model"
      ],
      "metadata": {
        "id": "zMyxVpqI4tdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "if install_deepseek==False:\n",
        "  # Define the path to the model directory\n",
        "  model_path = '/content/drive/MyDrive/genaisys/HuggingFaceCache/models--unsloth--DeepSeek-R1-Distill-Llama-8B/snapshots/71f34f954141d22ccdad72a2e3927dddf702c9de'\n",
        "\n",
        "  # Record the start time\n",
        "  start_time = time.time()\n",
        "  # Load the tokenizer and model from the specified path\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
        "  model = AutoModelForCausalLM.from_pretrained(model_path, device_map='auto', torch_dtype='auto', local_files_only=True)\n",
        "\n",
        "  # Record the end time\n",
        "  end_time = time.time()\n",
        "\n",
        "  # Calculate the elapsed time\n",
        "  elapsed_time = end_time - start_time\n",
        "\n",
        "  print(f\"Time taken to load the model: {elapsed_time:.2f} seconds\")"
      ],
      "metadata": {
        "id": "uyWIUDSt3_2k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "751185796314473f9087cacb971c0933",
            "1294c2b9211f4c8a8871ed0228cb82dd",
            "691ff290898249b28dd9dd251b0c3691",
            "c43241ee018d426aa8eb5177676664c8",
            "9e160081fa00479c9b4a49fd706f2d71",
            "b8698950f901495189757a0285ca4f6a",
            "47d4f1c1740941959a30b2d7f38a50f5",
            "5f6a4d6f8d854c75baafe041d2da72da",
            "f779a1a590414dd2afb28474449af582",
            "4eb0e7ca7ce84e73b3dd9cdb0f6c8a06",
            "9f1bd40c562040a8b9fe1d4d1905a794"
          ]
        },
        "outputId": "17ba1cce-893e-42fa-bbff-fa48683df56e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "751185796314473f9087cacb971c0933"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken to load the model: 14.71 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if install_deepseek==False:\n",
        "  print(model.config)"
      ],
      "metadata": {
        "id": "jSgiBU2m8rJJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17a92382-85fc-4863-9e2d-0fdfc676204b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlamaConfig {\n",
            "  \"_attn_implementation_autoset\": true,\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/genaisys/HuggingFaceCache/models--unsloth--DeepSeek-R1-Distill-Llama-8B/snapshots/71f34f954141d22ccdad72a2e3927dddf702c9de\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pad_token_id\": 128004,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 8.0,\n",
            "    \"high_freq_factor\": 4.0,\n",
            "    \"low_freq_factor\": 1.0,\n",
            "    \"original_max_position_embeddings\": 8192,\n",
            "    \"rope_type\": \"llama3\"\n",
            "  },\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.48.3\",\n",
            "  \"unsloth_fixed\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt"
      ],
      "metadata": {
        "id": "QTSNYBCb4vtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if install_deepseek==False:\n",
        "  prompt=\"\"\"\n",
        "  Explain how a product designer could transformer customer requirements for a traveling bag into a production plan.\n",
        "  \"\"\""
      ],
      "metadata": {
        "id": "t99pgv0IQ30m"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "if install_deepseek==False:\n",
        "  # Record the start time\n",
        "  start_time = time.time()\n",
        "\n",
        "\n",
        "  # Tokenize the input\n",
        "  inputs = tokenizer(prompt, return_tensors='pt').to('cuda')\n",
        "\n",
        "  # Generate output with enhanced anti-repetition settings\n",
        "  outputs = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=1200,\n",
        "    repetition_penalty=1.5,             # Increase penalty to 1.5 or higher\n",
        "    no_repeat_ngram_size=3,             # Prevent repeating n-grams of size 3\n",
        "    temperature=0.6,                    # Reduce randomness slightly\n",
        "    top_p=0.9,                          # Nucleus sampling for diversity\n",
        "    top_k=50                            # Limits token selection to top-k probable tokens\n",
        "  )\n",
        "\n",
        "  # Decode and display the output\n",
        "  generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "  # Record the end time\n",
        "  end_time = time.time()\n",
        "\n",
        "  # Calculate the elapsed time\n",
        "  elapsed_time = end_time - start_time\n",
        "\n",
        "  print(f\"Time taken to load the model: {elapsed_time:.2f} seconds\")\n",
        "\n",
        "  #print(generated_text)"
      ],
      "metadata": {
        "id": "Qt9GTrB34r2j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fe0c6af-7be4-4976-c757-00a9b270d0f4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken to load the model: 48.78 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "if install_deepseek==False:\n",
        "  # Assuming 'generated_text' contains the text you want to format\n",
        "  wrapped_text = textwrap.fill(generated_text, width=80)  # Adjust 'width' as needed\n",
        "\n",
        "  print(wrapped_text)\n"
      ],
      "metadata": {
        "id": "p4QX8niIK6Hr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e2c5dfa-42c1-44eb-e244-ef00f56fce9b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Explain how a product designer could transformer customer requirements for a\n",
            "traveling bag into a production plan.       The process involves understanding\n",
            "the user's needs, defining specifications through collaboration with\n",
            "manufacturers and suppliers to ensure quality standards are met. Finally,\n",
            "creating detailed blueprints that guide manufacturing.  Okay, so I need to\n",
            "explain step-by-step how aproduct designer transformscustomer\n",
            "requirementstoaproductionplanforatripplingbag.Let me think aboutthisprocessand\n",
            "break it down in my mind first.I guess starting fromthebeginningwhen someone\n",
            "wantsto createa newtraveling袋，they must talktosthe客户或者用户了解他们的具体需求。那么，这个过程是怎样的呢？\n",
            "首先，我应该考虑与顾客进行沟通和理解其真实需要。这可能包括讨论该背包将用于何种场合，是轻便、耐用还是有其他特性。\n",
            "接下来，或许会收集所有必要信息，如尺寸要求（宽度、高度）、重量限制，以及材料偏好。此外，还要关注功能方面的问题，比如是否带拉链，有没有内部 pockets\n",
            "或者多条肩绑等设计元素。  然后，将这些整理成一个详细且清晰的产品规格说明书，以供制造商参考。在这个阶段，也很重要的是确保每一项都被准确定义，没有遗漏或误解的地\n",
            "方。如果出现不清楚之处，最好的方法就是回去向客户澄清，所以这也是关键的一步。  之后，就可以开始在脑海中构思如何把这些函数转化为物理形态了。一位优秀的手工艺品店\n",
            "主通常有一套工具箱，其中包含各种草图纸张，不同类型笔记本以及模板来帮助记录想法。我觉得这里最难能可贵的事情，就是能够精准地捕捉到那些小而至关紧密的点，让整个旅装\n",
            "看起来既美观又实用的结构安排。  当你对大致概念满意后，你就得让生产部门知道你的计划，并提供足够的技术资料给供应商们审阅并准备投入生产。但为了避免任何问题发生，\n",
            "一定是在这一环节做充分的事前核查工作，看到了吗？比方说，如果某些部件无法按时获得，那么必须提早寻找替代方案；如果颜色协调上存在困扰，可以预见不同的批次间隔时间以\n",
            "达到最佳效果……  最后，当一切制作完毕，又因为质量控制非常严谨，每一步骤都会经过检查，从原料采购再检验零配，然后组装完成后的全面检测。而只有经受过这样系统性的\n",
            "审核程序才能保证出厂前的100%合格率，使消费者的使用体验更加顺畅愉快哦！  总结一下吧：从最初的一个简单的小目标逐渐展开，但却不可忽视其中无数需注意事项，只依\n",
            "靠经验是不行啦！还真是挺复杂的嘛，要兼顾创造力也不能少，而执行上的各类考量更是一个挑战。不过只要按照这样的流程慢慢推进的话，说不定真的可以成功打造那款令人喜爱的\n",
            "地道旅行用品！ </think>  **Step-by-Step Explanation:**  1. **Understanding Customer\n",
            "Requirements**     - Engage directly with customers or users via surveys,\n",
            "interviews, or focus groups to gather insights on their specific travel luggage\n",
            "demands such as size (width, height), weight capacity, material preferences,\n",
            "intended use case scenarios like business vs leisure travel, durability\n",
            "expectations, design features desired including zippers, compartments, handles,\n",
            "etc., color schemes if any preference is indicated by them.  2. **Defining\n",
            "Product Specifications**     Once all necessary information has been collected:\n",
            "3. Collaborate closely with manufacturers/suppliers to confirm feasibility of\n",
            "each feature based on available materials technology and processes; discuss\n",
            "potential challenges early on ensuring alignment between client vision &\n",
            "manufacturable designs without compromising functionality; 4. Create\n",
            "comprehensive technical drawings/blueprint using CAD software tools highlighting\n",
            "every critical dimension detail placement structure allowing precise replication\n",
            "during massproduction； 5. Establish strict QC criteria at various\n",
            "stages—rawmaterial inspection component assembly final integration—to maintain\n",
            "consistency throughout the entire lifecycle;  6.Present finalized plans to\n",
            "stakeholders obtaining approval before moving forward ensures smooth transition\n",
            "towards actual manufacturing phase.  7.Managing Production Process Efficiently：\n",
            "8.Monitor progress regularly reviewing samples when feasible catching issues\n",
            "promptly addressing deviations quickly preventing costly reworks downstream\n",
            "which can significantly impact timelines budgets while maintaining high-quality\n",
            "standardsthus maximizing productivity efficiency within supply chain network.\n",
            "9.Implementation Quality Control Checks Throughout Each Stage Ensuring Every\n",
            "Component Meets Precise Specifications Performed By Skilled Inspectors To\n",
            "Maintain Consistency And Reliability In Final Products Reducing The Risk Of\n",
            "Returns Or Complaints Post-Launch Due To Substandard Materials/Workmanship.\n",
            "10.Documentation archiving All Aspects From Design Changes Made During\n",
            "Manufacturing Through Testing Data Results Essential For Future Enhancements\n",
            "Iterations Improvements While Keeping Detailed Records Facilitating Compliance\n",
            "Audits Traceability If Required Down Line Should They Occur SuchAs Recall\n",
            "Processes Etcetera.  11.Final Review Approval Before Release Sign Off On\n",
            "Finished Goods Only After Full Satisfaction With Outcome Confirm That It Exceeds\n",
            "Expectations Delivering Unparalleled User Experience ReflectiveOf Thorough\n",
            "Planning Execution Precision Craftsmanship Attention Detail Orientation\n",
            "CommitmentToQualityThatSetsThisProduct ApartInMarketplaceCompetitionOutshinesRiv\n",
            "alsWithSuperiorDesignFunctionalityAndDurabilityEnsuresLongTermCustomerSatisfacti\n",
            "onBuildingTrustBrandLoyaltyandin turnDrivingRepeatBusinessGrowthForCompany\n"
          ]
        }
      ]
    }
  ]
}