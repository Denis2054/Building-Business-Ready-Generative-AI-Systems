{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyM9CWypz9qP248p1roSQku0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4bac450b44ee4edfa237f75003859339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f70b18e9881493abe9548d95c8b972b",
              "IPY_MODEL_d25e482f97204e30a7c6179af0c12553",
              "IPY_MODEL_4b0f2534fac54ccd9a91cc6e9132f7f7"
            ],
            "layout": "IPY_MODEL_d553d9cfd80d4c8a95a376d77ec7732d"
          }
        },
        "4f70b18e9881493abe9548d95c8b972b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c74229c5095c4532807dc30b65fdeadc",
            "placeholder": "​",
            "style": "IPY_MODEL_3f5103f0852b46d3ac382320833e1f1d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "d25e482f97204e30a7c6179af0c12553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebe3481de6594ce284fba8d4936242c9",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eecb22adbdbd4a1b81b6582225832af3",
            "value": 4
          }
        },
        "4b0f2534fac54ccd9a91cc6e9132f7f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c81ae0b6822493b9a993ca63dde8c60",
            "placeholder": "​",
            "style": "IPY_MODEL_c8a9db02e14f479fa92b756f24568924",
            "value": " 4/4 [01:54&lt;00:00, 25.33s/it]"
          }
        },
        "d553d9cfd80d4c8a95a376d77ec7732d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c74229c5095c4532807dc30b65fdeadc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f5103f0852b46d3ac382320833e1f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebe3481de6594ce284fba8d4936242c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eecb22adbdbd4a1b81b6582225832af3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c81ae0b6822493b9a993ca63dde8c60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8a9db02e14f479fa92b756f24568924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b43c9c1b2cf2429ca44773bc5124cf8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89fbe6c22fc347409a768bed2c70e858",
              "IPY_MODEL_302464b059544d11915c8d2bd83176ac",
              "IPY_MODEL_9485a729aeb9462c9ef91fd488a15b88",
              "IPY_MODEL_539651c8eabb466ba68ccd5ee592ec07",
              "IPY_MODEL_3e58eda3893d4e8b858eb9e048dfc34d",
              "IPY_MODEL_1d7586b3e2334ec5b42d31c8996da352",
              "IPY_MODEL_46ffe36735054d2ea528913118006f9a",
              "IPY_MODEL_245479dfc48542e9a463b752c66c7441"
            ],
            "layout": "IPY_MODEL_b1211ec6c94142cab077debf2d197a47"
          }
        },
        "89fbe6c22fc347409a768bed2c70e858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "User01",
              "User02",
              "User03"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "User:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_83cb3bccc9b04e5098ef2b8876478227",
            "style": "IPY_MODEL_e85effd865b54e6c9d26d5b16ea6c441"
          }
        },
        "302464b059544d11915c8d2bd83176ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_65913d1207d943b9ba10f46f9d0e7b1b",
            "placeholder": "Type your message here or type 'exit' or 'quit' to end the conversation.",
            "rows": null,
            "style": "IPY_MODEL_8a6751de6ec74f6d932ad1bcb0596a16",
            "value": ""
          }
        },
        "9485a729aeb9462c9ef91fd488a15b88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "primary",
            "description": "Send",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_5235947249a148b486d50ff9d575650d",
            "style": "IPY_MODEL_dfd323a08338413381476987dbd294db",
            "tooltip": ""
          }
        },
        "539651c8eabb466ba68ccd5ee592ec07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Agent",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_a7dd68d0048d450fa4ef181c82306715",
            "style": "IPY_MODEL_885852eb967645aa952f32389257c36c",
            "value": true
          }
        },
        "3e58eda3893d4e8b858eb9e048dfc34d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Voice Output",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_2e59bff9307e4eee801da17f361492dd",
            "style": "IPY_MODEL_9cd5a8fda86642a9a2630a3cf32b7cde",
            "value": false
          }
        },
        "1d7586b3e2334ec5b42d31c8996da352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Files",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_6f9a737debf74c528aa72b27fe6fb461",
            "style": "IPY_MODEL_8e849132ebd24af9af5ead1c8eca62bd",
            "value": false
          }
        },
        "46ffe36735054d2ea528913118006f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "None",
              "Analysis",
              "Generation",
              "Mobility"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Reasoning:",
            "description_tooltip": null,
            "disabled": false,
            "index": 3,
            "layout": "IPY_MODEL_0c1df8948ca14b86903e3ba2f58e1796",
            "style": "IPY_MODEL_efd3ec77daea4561970bfeaf8e6b1dec"
          }
        },
        "245479dfc48542e9a463b752c66c7441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "OpenAI",
              "DeepSeek"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Model:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_d82e2f26e2f140d284b96b2a3ff4bf5c",
            "style": "IPY_MODEL_8e1b09c19c814115b785beb120392c43"
          }
        },
        "b1211ec6c94142cab077debf2d197a47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "flex-start",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "83cb3bccc9b04e5098ef2b8876478227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "e85effd865b54e6c9d26d5b16ea6c441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65913d1207d943b9ba10f46f9d0e7b1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "100px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "8a6751de6ec74f6d932ad1bcb0596a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5235947249a148b486d50ff9d575650d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfd323a08338413381476987dbd294db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "a7dd68d0048d450fa4ef181c82306715": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20%"
          }
        },
        "885852eb967645aa952f32389257c36c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e59bff9307e4eee801da17f361492dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20%"
          }
        },
        "9cd5a8fda86642a9a2630a3cf32b7cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f9a737debf74c528aa72b27fe6fb461": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20%"
          }
        },
        "8e849132ebd24af9af5ead1c8eca62bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c1df8948ca14b86903e3ba2f58e1796": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "efd3ec77daea4561970bfeaf8e6b1dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d82e2f26e2f140d284b96b2a3ff4bf5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "8e1b09c19c814115b785beb120392c43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f8ba201d8714019a7bbf85c6e92c2cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89fbe6c22fc347409a768bed2c70e858",
              "IPY_MODEL_302464b059544d11915c8d2bd83176ac",
              "IPY_MODEL_9485a729aeb9462c9ef91fd488a15b88",
              "IPY_MODEL_539651c8eabb466ba68ccd5ee592ec07",
              "IPY_MODEL_3e58eda3893d4e8b858eb9e048dfc34d",
              "IPY_MODEL_1d7586b3e2334ec5b42d31c8996da352",
              "IPY_MODEL_46ffe36735054d2ea528913118006f9a",
              "IPY_MODEL_245479dfc48542e9a463b752c66c7441"
            ],
            "layout": "IPY_MODEL_78fea47e8f2d4084b7b4c84659476f40"
          }
        },
        "78fea47e8f2d4084b7b4c84659476f40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "flex-start",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "fb8ad19474294fa0b1998a3a6e9b13d0": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_7dc80a2e370044f4a88f68a43febde13",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Process completed.\n"
                ]
              }
            ]
          }
        },
        "7dc80a2e370044f4a88f68a43febde13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": "1px solid black",
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": "10px",
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": "10px",
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "5cab07aaee9e45689a323f329dd4c733": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_2f314036fdeb4064b10b2970ffad2746",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Process: the mobility agent is thinking\n",
                  "\n"
                ]
              }
            ]
          }
        },
        "2f314036fdeb4064b10b2970ffad2746": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": "1px solid black",
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": "10px",
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": "10px",
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "c57a0ef58fb643e0b8891564558f0fa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89fbe6c22fc347409a768bed2c70e858",
              "IPY_MODEL_302464b059544d11915c8d2bd83176ac",
              "IPY_MODEL_9485a729aeb9462c9ef91fd488a15b88",
              "IPY_MODEL_539651c8eabb466ba68ccd5ee592ec07",
              "IPY_MODEL_3e58eda3893d4e8b858eb9e048dfc34d",
              "IPY_MODEL_1d7586b3e2334ec5b42d31c8996da352",
              "IPY_MODEL_46ffe36735054d2ea528913118006f9a",
              "IPY_MODEL_245479dfc48542e9a463b752c66c7441"
            ],
            "layout": "IPY_MODEL_3952ea9839c442cdb1771ecf9e06f621"
          }
        },
        "3952ea9839c442cdb1771ecf9e06f621": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "flex-start",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "da90a85d466a4e0c9c25c019e07be9e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89fbe6c22fc347409a768bed2c70e858",
              "IPY_MODEL_302464b059544d11915c8d2bd83176ac",
              "IPY_MODEL_9485a729aeb9462c9ef91fd488a15b88",
              "IPY_MODEL_539651c8eabb466ba68ccd5ee592ec07",
              "IPY_MODEL_3e58eda3893d4e8b858eb9e048dfc34d",
              "IPY_MODEL_1d7586b3e2334ec5b42d31c8996da352",
              "IPY_MODEL_46ffe36735054d2ea528913118006f9a",
              "IPY_MODEL_245479dfc48542e9a463b752c66c7441"
            ],
            "layout": "IPY_MODEL_d41bad43e25849008894226029e42916"
          }
        },
        "d41bad43e25849008894226029e42916": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "flex-start",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "6e18b6d9eee340e8a9e24b32ac8bc7f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89fbe6c22fc347409a768bed2c70e858",
              "IPY_MODEL_302464b059544d11915c8d2bd83176ac",
              "IPY_MODEL_9485a729aeb9462c9ef91fd488a15b88",
              "IPY_MODEL_539651c8eabb466ba68ccd5ee592ec07",
              "IPY_MODEL_3e58eda3893d4e8b858eb9e048dfc34d",
              "IPY_MODEL_1d7586b3e2334ec5b42d31c8996da352",
              "IPY_MODEL_46ffe36735054d2ea528913118006f9a",
              "IPY_MODEL_245479dfc48542e9a463b752c66c7441"
            ],
            "layout": "IPY_MODEL_bbac8947472046749d090ee45102ccbe"
          }
        },
        "bbac8947472046749d090ee45102ccbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "flex-start",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **GenAISys with DeepSeek and OpenAI**  \n",
        "\n",
        "📌 **Copyright 2025, Denis Rothman**  \n",
        "\n",
        "---\n",
        "\n",
        "## **Welcome to GenAISys: A Cutting-Edge Generative AI System**  \n",
        "\n",
        "This notebook introduces **GenAISys**, a powerful Generative AI System that seamlessly integrates **DeepSeek** and **OpenAI**.  \n",
        "\n",
        "### **TheGenerative AI System(GenAISys) features**  \n",
        "🚀 **Advanced Generative AI** – Combining **DeepSeek** and **OpenAI’s o3-mini**  \n",
        "🧠 **Agentic Decision-Making** – Intelligent AI-driven reasoning  \n",
        "📚 **Retrieval-Augmented Generation (RAG)** – Powered by **Pinecone** for enhanced retrieval  \n",
        "📊 **Machine Learning & Analytics** – Structured memory encoding, sentiment analysis, and dynamic handler selection  \n",
        "\n",
        "By leveraging neuroscientific memory modeling and retrieval-enhanced processing, GenAISys optimizes AI interactions with cutting-edge **Memory-Augmented and Retrieval-Based Reasoning**.\n",
        "\n",
        "---\n",
        "\n",
        "## **🔧 DeepSeek Installation**  \n",
        "Before running this notebook, you **must install the DeepSeek reasoning model**.  \n",
        "\n",
        "🔗 **Run this notebook** → [Getting_started_with_DeepSeek_R1_Distill_Llama_8B.ipynb](https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/blob/main/Chapter07/Getting_started_with_DeepSeek_R1_Distill_Llama_8B.ipynb)  \n",
        "\n",
        "📌 **One-Click Execution** – Run all cells, then proceed to the **\"GenAISys IPython interface\"** section to launch the interactive AI system.\n",
        "\n",
        "---\n",
        "\n",
        "## **📖 Table of Contents**  \n",
        "\n",
        "### **1️⃣ Setting Up the Environment**  \n",
        "📂 File Downloading Script  \n",
        "\n",
        "### **2️⃣ Configuring DeepSeek (Hugging Face)**  \n",
        "✅ Checking GPU Activation  \n",
        "💾 Activating Cache in Google Drive  \n",
        "⚙️ Installing Hugging Face Environment  \n",
        "🔄 Checking Transformer Version  \n",
        "📌 Model Setup  \n",
        "\n",
        "### **3️⃣ OpenAI Integration**  \n",
        "🔧 Installing OpenAI  \n",
        "🔑 Initializing OpenAI API Key  \n",
        "📡 Importing the API Call Function  \n",
        "\n",
        "### **4️⃣ Installing gTTS**  \n",
        "🗣️ Setting Up Text-to-Speech (TTS)  \n",
        "\n",
        "### **5️⃣ Machine Learning**  \n",
        "🧠 ML Techniques for AI Reasoning  \n",
        "\n",
        "### **6️⃣ Chain of Thought (CoT) Reasoning**  \n",
        "🔍 Implementing Step-by-Step AI Thought Processing  \n",
        "\n",
        "### **7️⃣ Pinecone for Retrieval-Augmented Generation (RAG)**  \n",
        "🔑 Initializing the Pinecone API Key  \n",
        "📂 Setting Up the Pinecone Index  \n",
        "🔎 Querying Functions for AI Memory Retrieval  \n",
        "\n",
        "### **8️⃣ The AI Agent: Intelligence in Action**  \n",
        "🛠️ Defining AI Functions  \n",
        "📚 Handler Registry for Decision-Making  \n",
        "🎯 Dynamic Handler Selection Mechanism  \n",
        "\n",
        "### **9️⃣ The GenAISys IPython Interface**  \n",
        "▶️ **Running the Interface** – Interactive AI Execution  \n",
        "📜 **IPython Interactive Guide** – User-friendly AI Interaction  \n",
        "📖 **Load & Display Conversation History** – Review Past Interactions  \n",
        "📊 **Summarizing the Conversation History** – AI-Powered Insights  \n",
        "\n",
        "---\n",
        "\n",
        "### **💡 Experience GenAISys**\n",
        "Run the whole notebook and then run the **IPython interface** for a **Generative AI experience**🚀"
      ],
      "metadata": {
        "id": "rA2_SNjzA4Dc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up the environment"
      ],
      "metadata": {
        "id": "vub82Rjxa17a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zHjDOMWo9Blf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afc444e7-beb2-4115-9e8b-f63ffdfe7b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## File downloading script\n",
        "\n",
        "grequests contains a script to download files from the repository"
      ],
      "metadata": {
        "id": "S8_G2ePO11rQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Private repository notes\n",
        "#1.This line will be deleted when the repository is made public and the following line will be uncommented\n",
        "#2.The private token will also be removed from grequests.py in the commmons directory of the repository\n",
        "!curl -L -H \"Authorization: Bearer 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\" https://raw.githubusercontent.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/master/commons/grequests.py --output grequests.py"
      ],
      "metadata": {
        "id": "P4_26Hfdx2kX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b33479a9-681d-49a8-e6b3-a2d117a8bac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1008  100  1008    0     0   4803      0 --:--:-- --:--:-- --:--:--  4822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!curl -L https://raw.githubusercontent.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/master/commons/grequests.py --output grequests.py"
      ],
      "metadata": {
        "id": "vzkCTNNChWAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up the DeepSeek Hugging Face environment"
      ],
      "metadata": {
        "id": "mA0_omNcKCw4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking GPU activation"
      ],
      "metadata": {
        "id": "2WX2FRUyvnmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "8Lnpx8Ywvkqu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e91f4c7-d73b-4a94-88d6-b23f9e2ee983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Feb  9 12:12:48 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0             42W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Activate cache in Google Drive"
      ],
      "metadata": {
        "id": "87z54INBvyUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the cache directory in your Google Drive\n",
        "cache_dir = '/content/drive/MyDrive/genaisys/HuggingFaceCache'\n",
        "\n",
        "# Set environment variables to direct Hugging Face to use this cache directory\n",
        "os.environ['TRANSFORMERS_CACHE'] = cache_dir\n",
        "#os.environ['HF_DATASETS_CACHE'] = os.path.join(cache_dir, 'datasets')"
      ],
      "metadata": {
        "id": "TzzNqXIRCSxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installation Hugging Face environment\n",
        "\n",
        "Path in this notebook: drive/MyDrive/genaisys/\n"
      ],
      "metadata": {
        "id": "hk_OMj3Xv7H6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip transformers"
      ],
      "metadata": {
        "id": "07XwZO2Bx1sZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02e8fb93-db4d-406d-c83c-5f33cff4ca3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR: unknown command \"transformers\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking transformer version"
      ],
      "metadata": {
        "id": "yKXESfW5zzpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(transformers.__version__)"
      ],
      "metadata": {
        "id": "-0uKNItkz_0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa684032-9264-4eb2-e095-a5e8f0c45523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.48.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "zMyxVpqI4tdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Define the path to the model directory\n",
        "model_path = '/content/drive/MyDrive/genaisys/HuggingFaceCache/models--unsloth--DeepSeek-R1-Distill-Llama-8B/snapshots/71f34f954141d22ccdad72a2e3927dddf702c9de'\n",
        "\n",
        "# Record the start time\n",
        "start_time = time.time()\n",
        "# Load the tokenizer and model from the specified path\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path, device_map='auto', torch_dtype='auto', local_files_only=True)\n",
        "\n",
        "# Record the end time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(f\"Time taken to load the model: {elapsed_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "id": "uyWIUDSt3_2k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "4bac450b44ee4edfa237f75003859339",
            "4f70b18e9881493abe9548d95c8b972b",
            "d25e482f97204e30a7c6179af0c12553",
            "4b0f2534fac54ccd9a91cc6e9132f7f7",
            "d553d9cfd80d4c8a95a376d77ec7732d",
            "c74229c5095c4532807dc30b65fdeadc",
            "3f5103f0852b46d3ac382320833e1f1d",
            "ebe3481de6594ce284fba8d4936242c9",
            "eecb22adbdbd4a1b81b6582225832af3",
            "1c81ae0b6822493b9a993ca63dde8c60",
            "c8a9db02e14f479fa92b756f24568924"
          ]
        },
        "outputId": "0412b35e-6cf4-4200-9f7e-e1269dba682a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bac450b44ee4edfa237f75003859339"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken to load the model: 124.32 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "# Retrieve the Hugging Face token from Colab's Secrets Manager\n",
        "userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "lG45BHPj1Thc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "23225858-ac88-4105-eeba-ca86c3c0a240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'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'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI"
      ],
      "metadata": {
        "id": "jmmBBZ7oa17b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from grequests import download\n",
        "download(\"commons\",\"requirements01.py\")\n",
        "download(\"commons\",\"openai_setup.py\")\n",
        "download(\"commons\",\"reason.py\")\n",
        "download(\"commons\",\"machine_learning.py\")\n",
        "download(\"commons\",\"genaisys.html\")"
      ],
      "metadata": {
        "id": "G_PuE5rjhWAK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5fc87de-7e56-438f-d2e9-ae4e20aa837b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 'requirements01.py' successfully.\n",
            "Downloaded 'openai_setup.py' successfully.\n",
            "Downloaded 'reason.py' successfully.\n",
            "Downloaded 'machine_learning.py' successfully.\n",
            "Downloaded 'genaisys.html' successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing OpenAI"
      ],
      "metadata": {
        "id": "9kNLfjTfAnFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the setup script to install and import dependencies\n",
        "%run requirements01"
      ],
      "metadata": {
        "id": "a7i8j5vnpatH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3d7a01d-e5b2-4d2e-adfc-883dd70af864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uninstalling 'openai'...\n",
            "Installing 'openai' version 1.57.1...\n",
            "'openai' version 1.57.1 is installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initializing the OpenAI API key\n",
        "\n"
      ],
      "metadata": {
        "id": "O03SZzGGAreV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "google_secrets=True #activates Google secrets in Google Colab\n",
        "if google_secrets==True:\n",
        "  import openai_setup\n",
        "  openai_setup.initialize_openai_api()"
      ],
      "metadata": {
        "id": "pDn09vPbAXPT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "787cf52d-5fb1-4782-bc33-b2eb5a7201c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API key initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if google_secrets==False: # Uncomment the code and choose any method you wish to initialize the API_KEY\n",
        "  import os\n",
        "  #API_KEY=[YOUR API_KEY]\n",
        "  #os.environ['OPENAI_API_KEY'] = API_KEY\n",
        "  #openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "  #print(\"OpenAI API key initialized successfully.\")"
      ],
      "metadata": {
        "id": "C3398f_cetsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NL93eSL-mLi"
      },
      "source": [
        "#### Importing the API call function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the function from the custom OpenAI API file\n",
        "import os\n",
        "import reason\n",
        "from reason import make_openai_api_call\n",
        "from reason import make_openai_reasoning_call"
      ],
      "metadata": {
        "id": "0lMhv09G0kzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing gtts\n",
        "\n",
        "gTTS (Google Text-to-Speech) is a Python library and CLI tool that interfaces with Google Translate's text-to-speech API. It allows users to convert text into spoken words, supporting multiple languages and accents, and can save the output as MP3 files.  "
      ],
      "metadata": {
        "id": "pGpMI-5iLFMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gTTS==2.5.4"
      ],
      "metadata": {
        "id": "_XpDBL-cLHTT",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d641051a-2960-4473-ef9e-10b01510b387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gTTS==2.5.4\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from gTTS==2.5.4) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.11/dist-packages (from gTTS==2.5.4) (8.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS==2.5.4) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS==2.5.4) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS==2.5.4) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS==2.5.4) (2025.1.31)\n",
            "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: gTTS\n",
            "Successfully installed gTTS-2.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "import numpy as np\n",
        "\n",
        "def text_to_speech(text):\n",
        "    # Convert text to speech and save as an MP3 file\n",
        "    tts = gTTS(text)\n",
        "    tts.save(\"response.mp3\")"
      ],
      "metadata": {
        "id": "mVLHE2xaBuL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine learning"
      ],
      "metadata": {
        "id": "yWL8u0g8Em1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the function from the custom OpenAI API file\n",
        "import os\n",
        "import machine_learning\n",
        "from machine_learning import ml_agent"
      ],
      "metadata": {
        "id": "edZKk7Q2FzVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain of Thought(COT)"
      ],
      "metadata": {
        "id": "UHjBYt-f6S4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the function from the custom OpenAI API file\n",
        "import os\n",
        "import reason\n",
        "from reason import chain_of_thought_reasoning\n",
        "from reason import memory_reasoning_thread # import memory reasoning thread96"
      ],
      "metadata": {
        "id": "5SLXIJHF6kTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AI agent : the messages and prompts for memory agent tasks\n",
        "download(\"commons\",\"cot_messages_c6.py\") # downloaded messages and prompts"
      ],
      "metadata": {
        "id": "-1m3IiYhzhov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fc7b3af-f4b4-49c5-aafa-c6a070cbbce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 'cot_messages_c6.py' successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QGI1D8FVrT6"
      },
      "source": [
        "## Installing Pinecone"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download(\"commons\",\"requirements02.py\")"
      ],
      "metadata": {
        "id": "F3ufJsT54EHe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d56532b-772e-4795-ab4b-1e4352c0a29b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 'requirements02.py' successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Z2abuU9OkVFL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0c52cd6-a66e-48c2-fdfc-baffd0ee3421"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uninstalling 'pinecone-client'...\n",
            "Installing 'pinecone-client' version 5.0.1...\n",
            "'pinecone-client' version 5.0.1 is installed.\n"
          ]
        }
      ],
      "source": [
        "# Run the setup script to install and import dependencies\n",
        "%run requirements02"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializing the Pinecone API key"
      ],
      "metadata": {
        "id": "tum9Jd1odcNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "download(\"commons\",\"pinecone_setup.py\")"
      ],
      "metadata": {
        "id": "2eIyjdd25LjH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3eb6e29-5297-450e-8b97-78b36474d1f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 'pinecone_setup.py' successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if google_secrets==True:\n",
        "  import pinecone_setup\n",
        "  pinecone_setup.initialize_pinecone_api()"
      ],
      "metadata": {
        "id": "0zPS_mgsdXKj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2df1ac1-05ec-4688-8e23-39488fc88175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PINECONE_API_KEY initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if google_secrets==False: # Uncomment the code and choose any method you wish to initialize the Pinecone API key\n",
        "  import os\n",
        "  #PINECONE_API_KEY=[YOUR PINECONE_API_KEY]\n",
        "  #os.environ['PINECONE_API_KEY'] = PINECONE_API_KEY\n",
        "  #openai.api_key = os.getenv(\"PINECONE_API_KEY\")\n",
        "  #print(\"OpenAI API key initialized successfully.\")"
      ],
      "metadata": {
        "id": "D-dJTlEn_FZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XswfiN5Z1OvT"
      },
      "source": [
        "##  The Pinecone index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "# Retrieve the API key from environment variables\n",
        "api_key = os.environ.get('PINECONE_API_KEY')\n",
        "if not api_key:\n",
        "    raise ValueError(\"PINECONE_API_KEY is not set in the environment!\")\n",
        "\n",
        "# Initialize the Pinecone client\n",
        "pc = Pinecone(api_key=api_key)"
      ],
      "metadata": {
        "id": "cKCvBbZPTIjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P---PNLpXeQs"
      },
      "outputs": [],
      "source": [
        "from pinecone import ServerlessSpec\n",
        "\n",
        "index_name = 'genai-v1'\n",
        "cloud = os.environ.get('PINECONE_CLOUD') or 'aws'\n",
        "region = os.environ.get('PINECONE_REGION') or 'us-east-1'\n",
        "\n",
        "spec = ServerlessSpec(cloud=cloud, region=region)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jO7AYljM0gq1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ebc63d0-5e39-4ec9-c3ce-bfb8f9a64de0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {'agent_memory': {'vector_count': 4},\n",
              "                'data01': {'vector_count': 9},\n",
              "                'genaisys': {'vector_count': 3}},\n",
              " 'total_vector_count': 16}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "import time\n",
        "import pinecone\n",
        "# check if index already exists (it shouldn't if this is first time)\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    # if does not exist, create index\n",
        "    pc.create_index(\n",
        "        index_name,\n",
        "        dimension=1536,  # dimension of the embedding model\n",
        "        metric='cosine',\n",
        "        spec=spec\n",
        "    )\n",
        "    # wait for index to be initialized\n",
        "    time.sleep(1)\n",
        "\n",
        "# connect to index\n",
        "index = pc.Index(index_name)\n",
        "# view index stats\n",
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Querying functions"
      ],
      "metadata": {
        "id": "9iIIeZB7RUDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_results(query_results):\n",
        "  for match in query_results['matches']:\n",
        "    print(f\"ID: {match['id']}, Score: {match['score']}\")\n",
        "    if 'metadata' in match and 'text' in match['metadata']:\n",
        "        text=match['metadata']['text']\n",
        "        #print(f\"Text: {match['metadata']['text']}\")\n",
        "        target_id = query_results['matches'][0]['id']  # Get the ID from the first match\n",
        "                #print(f\"Target ID: {target_id}\")\n",
        "    else:\n",
        "        print(\"No metadata available.\")\n",
        "  return text, target_id\n"
      ],
      "metadata": {
        "id": "NS2HWdO76iQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DT6wytGz5hTS"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "client = openai.OpenAI()\n",
        "embedding_model = \"text-embedding-3-small\"\n",
        "def get_embedding(text, model=embedding_model):\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    response = client.embeddings.create(input=[text], model=model)\n",
        "    embedding = response.data[0].embedding\n",
        "    return embedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_query_results(query_text, namespace):\n",
        "    # Generate the query vector from the query text\n",
        "    query_vector = get_embedding(query_text)  # Replace with your method to generate embeddings\n",
        "\n",
        "    # Perform the query\n",
        "    query_results = index.query(\n",
        "        vector=query_vector,\n",
        "        namespace=namespace,\n",
        "        top_k=1,  # Adjust as needed\n",
        "        include_metadata=True\n",
        "    )\n",
        "    # Return the results\n",
        "    return query_results"
      ],
      "metadata": {
        "id": "_FxS2Q0nnZAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_vector_store(query_text, namespace):\n",
        "    print(\"Querying vector store...\")\n",
        "\n",
        "    # Retrieve query results\n",
        "    query_results = get_query_results(query_text, namespace)\n",
        "\n",
        "    # Process and display the results\n",
        "    print(\"Processed query results:\")\n",
        "    text, target_id = display_results(query_results)\n",
        "\n",
        "    return text, target_id"
      ],
      "metadata": {
        "id": "-k5GxQGZSjlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI Agent"
      ],
      "metadata": {
        "id": "VesAR25Ywxcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deepseek=True\n",
        "if deepseek==True:\n",
        "  prompt=\"\"\"\n",
        " DeepSeek: 200,Sentiment analysis Read the content return a sentiment analysis nalysis on this text and provide a score with the label named : Sentiment analysis score followed by a numerical value between 0 and 1 with no + or - sign and add an explanation to justify the score. Let's see what Pinecone thinks about this sentence: The customer did not like the traveling bag we gave out for free.\n",
        "  \"\"\""
      ],
      "metadata": {
        "id": "AtB_DThq-o8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "if deepseek==True:\n",
        "  # Record the start time\n",
        "  start_time = time.time()\n",
        "\n",
        "\n",
        "  # Tokenize the input\n",
        "  inputs = tokenizer(prompt, return_tensors='pt').to('cuda')\n",
        "\n",
        "  # Generate output\n",
        "  outputs = model.generate(**inputs, max_new_tokens=1200)\n",
        "\n",
        "  # Decode and display the output\n",
        "  generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "  # Record the end time\n",
        "  end_time = time.time()\n",
        "\n",
        "  # Calculate the elapsed time\n",
        "  elapsed_time = end_time - start_time\n",
        "\n",
        "  print(f\"Time taken to load the model: {elapsed_time:.2f} seconds\")\n",
        "\n",
        "  print(generated_text)"
      ],
      "metadata": {
        "id": "Qt9GTrB34r2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "-gGgBHAbZCGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "from IPython.display import display, Image\n",
        "import requests\n",
        "\n",
        "# Initialize the OpenAI client\n",
        "client = OpenAI()\n",
        "user_memory = True  # True = User messages are memorized, False = User messages are not memorized\n",
        "\n",
        "# AI agent: Download messages and prompts\n",
        "download(\"commons\", \"cot_messages_c6.py\")  # Downloaded messages and prompts\n",
        "\n",
        "\n",
        "# Define Handler Functions\n",
        "def handle_pinecone_rag(user_message, **kwargs):\n",
        "    if \"Pinecone\" in user_message:\n",
        "      namespace = \"genaisys\"\n",
        "    if \"RAG\" in user_message:\n",
        "      namespace = \"data01\"\n",
        "\n",
        "    #print(namespace)\n",
        "\n",
        "    query_text = user_message\n",
        "    query_results = get_query_results(query_text, namespace)\n",
        "\n",
        "    print(\"Processed query results:\")\n",
        "    qtext, target_id = display_results(query_results)\n",
        "    print(qtext)\n",
        "\n",
        "    # Run task\n",
        "    sc_input = qtext + \" \" + user_message\n",
        "\n",
        "    models = kwargs.get(\"models\", \"OpenAI\")  # Default to OpenAI if not provided\n",
        "\n",
        "    if models == \"OpenAI\":\n",
        "      task_response = reason.make_openai_api_call(\n",
        "      sc_input, \"system\",\"You are an assistant who executes the tasks you are asked to do.\", \"user\")\n",
        "\n",
        "    if models == \"DeepSeek\":\n",
        "      # Tokenize the input\n",
        "      inputs = tokenizer(sc_input, return_tensors='pt').to('cuda')\n",
        "      # Generate output\n",
        "      outputs = model.generate(**inputs, max_new_tokens=1200)\n",
        "      # Decode the output\n",
        "      task_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return f\"{namespace}:{models}: {task_response}\"\n",
        "\n",
        "\n",
        "def handle_reasoning_customer(user_message, **kwargs):\n",
        "    initial_query = user_message\n",
        "    download(\"Chapter05\", \"customer_activities.csv\")\n",
        "\n",
        "    reasoning_steps = reason.chain_of_thought_reasoning(initial_query)\n",
        "    return reasoning_steps\n",
        "\n",
        "\n",
        "def handle_analysis(user_message, **kwargs):\n",
        "    from cot_messages_c6 import system_message_s1\n",
        "\n",
        "    models = kwargs.get(\"models\", \"OpenAI\")  # Default to OpenAI if not provided\n",
        "\n",
        "    if models == \"OpenAI\":\n",
        "      reasoning_steps = reason.make_openai_reasoning_call(user_message, system_message_s1)\n",
        "\n",
        "    if models == \"DeepSeek\":\n",
        "      # Tokenize the input\n",
        "      ds_input=system_message_s1+user_message\n",
        "      inputs = tokenizer(ds_input, return_tensors='pt').to('cuda')\n",
        "      # Generate output\n",
        "      outputs = model.generate(**inputs, max_new_tokens=1200)\n",
        "      # Decode the output\n",
        "      reasoning_steps = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return reasoning_steps\n",
        "\n",
        "\n",
        "def handle_generation(user_message, **kwargs):\n",
        "    from cot_messages_c6 import system_message_s1, generation, imcontent4, imcontent4b\n",
        "\n",
        "    reasoning_steps = reason.memory_reasoning_thread(user_message, system_message_s1, generation, imcontent4, imcontent4b)\n",
        "    return reasoning_steps\n",
        "\n",
        "def handle_mobility(user_message, **kwargs):\n",
        "     from cot_messages_c6 import msystem_message_s1, mgeneration, mimcontent4, mimcontent4b\n",
        "\n",
        "     reasoning_steps = reason.mobility_agent_reasoning_thread(user_message, msystem_message_s1, mgeneration, mimcontent4, mimcontent4b)\n",
        "     return reasoning_steps\n",
        "\n",
        "\n",
        "def handle_image_creation(user_message, **kwargs):\n",
        "    prompt = user_message\n",
        "    image_url = reason.generate_image(prompt, model=\"dall-e-3\", size=\"1024x1024\", quality=\"standard\", n=1)\n",
        "\n",
        "    # Save the image locally\n",
        "    save_path = \"c_image.png\"\n",
        "    image_data = requests.get(image_url).content\n",
        "    with open(save_path, \"wb\") as file:\n",
        "        file.write(image_data)\n",
        "\n",
        "    return \"Image created\"\n",
        "\n",
        "\n",
        "def handle_no_memory(user_message, **kwargs):\n",
        "    task_response = reason.make_openai_api_call(\n",
        "        user_message, \"system\",\n",
        "        \"You are an assistant who executes the tasks you are asked to do.\", \"user\"\n",
        "    )\n",
        "    return task_response\n",
        "\n",
        "\n",
        "def handle_with_memory(messages, user_message, **kwargs):\n",
        "    # Extract ALL user messages from the conversation history\n",
        "    user_messages_content = [\n",
        "        msg[\"content\"] for msg in messages if msg[\"role\"] == \"user\" and \"content\" in msg\n",
        "    ]\n",
        "    combined_user_messages = \" \".join(user_messages_content)\n",
        "\n",
        "    umessage = f\"{combined_user_messages} {user_message}\"\n",
        "\n",
        "    models = kwargs.get(\"models\", \"OpenAI\")  # Default to OpenAI if not provided\n",
        "\n",
        "    if models == \"OpenAI\":\n",
        "      task_response = reason.make_openai_api_call(\n",
        "        umessage, \"system\",\n",
        "        \"You are an assistant who executes the tasks you are asked to do.\", \"user\")\n",
        "\n",
        "    if models == \"DeepSeek\":\n",
        "      # Tokenize the input\n",
        "      sys1=\"You are an assistant who executes the tasks you are asked to do.\"\n",
        "      ds_input=sys1+umessage\n",
        "      inputs = tokenizer(ds_input, return_tensors='pt').to('cuda')\n",
        "      # Generate output\n",
        "      outputs = model.generate(**inputs, max_new_tokens=1200)\n",
        "      # Decode the output\n",
        "      task_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return task_response"
      ],
      "metadata": {
        "id": "AV1z3qUAEnbN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21be256f-3ea1-4bab-c182-eef739668317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 'cot_messages_c6.py' successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handler registry"
      ],
      "metadata": {
        "id": "3-QtPpjcY2W-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handler Registry\n",
        "handlers = [\n",
        "    (lambda msg, instruct, mem, models: \"Pinecone\" in msg or \"RAG\" in msg, handle_pinecone_rag),\n",
        "    (lambda msg, instruct, mem, models: all(keyword in msg for keyword in [\"Use reasoning\", \"customer\", \"activities\"]), handle_reasoning_customer),\n",
        "    (lambda msg, instruct, mem, models: instruct == \"Analysis\", handle_analysis),\n",
        "    (lambda msg, instruct, mem, models: instruct == \"Generation\", handle_generation),\n",
        "    (lambda msg, instruct, mem, models: instruct == \"Mobility\", handle_mobility),\n",
        "    (lambda msg, instruct, mem, models: \"Create\" in msg and \"image\" in msg, handle_image_creation),\n",
        "    (lambda msg, instruct, mem, models: not mem, handle_no_memory),\n",
        "    (lambda msg, instruct, mem, models: mem, handle_with_memory),\n",
        "]"
      ],
      "metadata": {
        "id": "6R8eghE5Yvx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handler selection mechanism"
      ],
      "metadata": {
        "id": "2-As05JvY8FP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handler Selection Mechanism\n",
        "def chat_with_gpt(messages, user_message, files_status, active_instruct, models):\n",
        "    try:\n",
        "        # Iterate over handlers and execute the first matching one\n",
        "        for condition, handler in handlers:\n",
        "            if condition(user_message, active_instruct, user_memory, models):  # Pass models\n",
        "                if handler == handle_with_memory:  # Only this handler needs `messages`\n",
        "                    return handler(messages, user_message, files_status=files_status, instruct=active_instruct, mem=user_memory, models=models)\n",
        "                else:  # Other handlers receive `models` in kwargs\n",
        "                    return handler(user_message, files_status=files_status, instruct=active_instruct, mem=user_memory, models=models)\n",
        "\n",
        "        # Default case if no handlers match\n",
        "        return \"No matching handler found.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred in the handler selection mechanism: {str(e)}\"\n"
      ],
      "metadata": {
        "id": "Q0Yxn5hhYx1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GenAISys IPython interface"
      ],
      "metadata": {
        "id": "4H8CPqQQCaEC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the interface\n",
        "\n",
        "Enter(do not copy and paste) \"Use reasoning\" + text to trigger Chain-of-Thought for this domain-specific notebook (traveling).\n",
        "\n",
        "For example:\n",
        "`Use reasoning to suggest activities for our customers.`"
      ],
      "metadata": {
        "id": "CW6YHIvZCii1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_json_as_markdown(data, level=0):\n",
        "    \"\"\"Format JSON-like data as Markdown with proper indentation.\"\"\"\n",
        "    html_output = \"\"\n",
        "    indent = \"  \" * level\n",
        "\n",
        "    if isinstance(data, dict):\n",
        "        for key, value in data.items():\n",
        "            html_output += f\"{indent}**{key}**:<br>\\n\"\n",
        "            html_output += format_json_as_markdown(value, level + 1)\n",
        "    elif isinstance(data, list):\n",
        "        for item in data:\n",
        "            html_output += format_json_as_markdown(item, level)\n",
        "    else:\n",
        "        html_output += f\"{indent}{data}<br>\\n\"\n",
        "\n",
        "    return html_output or \"\"  # Ensure a string is always returned"
      ],
      "metadata": {
        "id": "4iqA8Y1fEEn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_entry(entry):\n",
        "    \"\"\"Format the content of an entry for Markdown display.\"\"\"\n",
        "    if entry['role'] == 'user':\n",
        "        formatted_content = format_json_as_markdown(entry['content']) if isinstance(entry['content'], (dict, list)) else entry['content']\n",
        "        formatted_content = formatted_content.replace(\"\\n\", \"<br>\")  # Process newlines outside the f-string\n",
        "        return f\"**<span style='color: blue;'>{active_user}:</span>** {formatted_content}\"\n",
        "    elif entry['role'] == 'assistant':\n",
        "        formatted_content = format_json_as_markdown(entry['content']) if isinstance(entry['content'], (dict, list)) else entry['content']\n",
        "        formatted_content = formatted_content.replace(\"\\n\", \"<br>\")  # Process newlines outside the f-string\n",
        "        return f\"**<span style='color: green;'>Agent:</span>** {formatted_content}\"\n",
        "    else:\n",
        "        return entry['content']  # Fallback for unrecognized roles"
      ],
      "metadata": {
        "id": "S8b2--nsFQqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required modules\n",
        "from IPython.display import display, HTML, clear_output, Markdown\n",
        "from ipywidgets import Dropdown, Textarea, Button, Checkbox, VBox, Layout, Output\n",
        "from PIL import Image as PILImage\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Create an output widget for reasoning steps\n",
        "reasoning_output = Output(layout=Layout(border=\"1px solid black\", padding=\"10px\", margin=\"10px\", width=\"100%\"))\n",
        "\n",
        "# Initialize conversation histories for all users and active user\n",
        "user_histories = {\"User01\": [], \"User02\": [], \"User03\": []}\n",
        "active_user = \"User01\"  # Default user\n",
        "conversation_active = True\n",
        "\n",
        "# Function to handle user input and optional bot response\n",
        "def chat(user_message):\n",
        "    global conversation_active\n",
        "    if user_message.lower() in ['exit', 'quit']:\n",
        "        conversation_active = False\n",
        "        clear_output(wait=True)\n",
        "        display(HTML(\"<div style='color: red;'><strong>Conversation ended. Saving history...</strong></div>\"))\n",
        "        save_conversation_history()\n",
        "        display(HTML(\"<div style='color: green;'><strong>History saved. Proceed to the next cell.</strong></div>\"))\n",
        "        return\n",
        "\n",
        "    # Append user message to active user's history\n",
        "    user_histories[active_user].append({\"role\": \"user\", \"content\": user_message})\n",
        "\n",
        "    # Generate bot response if agent_checkbox is checked\n",
        "    if agent_checkbox.value:\n",
        "        pfiles = 1 if files_checkbox.value else 0\n",
        "        active_instruct = instruct_selector.value\n",
        "        selected_model = model_selector.value\n",
        "        response = chat_with_gpt(user_histories[active_user], user_message, pfiles, active_instruct, models=selected_model)\n",
        "\n",
        "        # Append bot response to active user's history\n",
        "        user_histories[active_user].append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "        # If TTS is enabled, convert response to speech\n",
        "        if tts_checkbox.value:\n",
        "            text_to_speech(response)\n",
        "\n",
        "    # Update display\n",
        "    update_display()\n",
        "\n",
        "# Function to update the display\n",
        "def update_display():\n",
        "    clear_output(wait=True)\n",
        "\n",
        "    for entry in user_histories[active_user]:\n",
        "        formatted_entry = format_entry(entry)\n",
        "        display(Markdown(formatted_entry))\n",
        "\n",
        "    # Display interactive widgets\n",
        "    if conversation_active:\n",
        "        display(\n",
        "            VBox(\n",
        "                [user_selector, input_box, submit_button, agent_checkbox, tts_checkbox, files_checkbox, instruct_selector, model_selector],\n",
        "                layout=Layout(display='flex', flex_flow='column', align_items='flex-start', width='100%')\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Display reasoning_output persistently\n",
        "    display(reasoning_output)\n",
        "\n",
        "# Function to handle submission (button click or Enter key)\n",
        "def handle_submission():\n",
        "    user_message = input_box.value.strip()  # Get input text\n",
        "    if user_message:\n",
        "        input_box.value = \"\"  # Clear input box\n",
        "\n",
        "        # Show \"Processing request...\" immediately\n",
        "        with reasoning_output:\n",
        "            reasoning_output.clear_output(wait=True)\n",
        "            print(\"Processing request...\")\n",
        "\n",
        "        # Check if instruct_selector is \"Analysis\" or \"Generation\"\n",
        "        if instruct_selector.value in [\"Analysis\", \"Generation\",\"Mobility\"]:\n",
        "            with reasoning_output:\n",
        "                reasoning_output.clear_output(wait=True)\n",
        "                print(\"Thinking...\")\n",
        "\n",
        "        # Process user message\n",
        "        chat(user_message)\n",
        "\n",
        "        # Indicate that processing is finished\n",
        "        with reasoning_output:\n",
        "            reasoning_output.clear_output(wait=True)\n",
        "            print(\"Process completed.\")\n",
        "\n",
        "# Function to handle submit button click\n",
        "def handle_button_click(sender):\n",
        "    handle_submission()\n",
        "\n",
        "# Function to handle Enter key press in the Textarea\n",
        "def handle_enter_key(change):\n",
        "    if change['new'].endswith(\"\\n\"):  # Detect Enter key press\n",
        "        handle_submission()\n",
        "\n",
        "# Function to update active user\n",
        "def on_user_change(change):\n",
        "    global active_user\n",
        "    active_user = change['new']\n",
        "    update_display()\n",
        "\n",
        "# Function to save conversation history to a file\n",
        "def save_conversation_history():\n",
        "    filename = \"conversation_history.json\"\n",
        "    with open(filename, 'w') as file:\n",
        "        json.dump(user_histories, file, indent=4)\n",
        "    display(HTML(f\"<div style='color: green;'><strong>Conversation history saved to {filename}.</strong></div>\"))\n",
        "\n",
        "# Create dropdown for user selection\n",
        "user_selector = Dropdown(\n",
        "    options=[\"User01\", \"User02\", \"User03\"],\n",
        "    value=active_user,\n",
        "    description='User:',\n",
        "    layout=Layout(width='50%')\n",
        ")\n",
        "user_selector.observe(on_user_change, names='value')\n",
        "\n",
        "# Create multi-line input box\n",
        "input_box = Textarea(\n",
        "    placeholder=\"Type your message here or type 'exit' or 'quit' to end the conversation.\",\n",
        "    layout=Layout(width='100%', height='100px')\n",
        ")\n",
        "\n",
        "# Create submit button\n",
        "submit_button = Button(description=\"Send\", button_style='primary')\n",
        "submit_button.on_click(handle_button_click)\n",
        "\n",
        "# Attach event handler for Enter key (FIXED)\n",
        "input_box.observe(handle_enter_key, names=\"value\")\n",
        "\n",
        "# Create checkboxes for toggles\n",
        "tts_checkbox = Checkbox(value=False, description='Voice Output', layout=Layout(width='20%'))\n",
        "files_checkbox = Checkbox(value=False, description='Files', layout=Layout(width='20%'))\n",
        "agent_checkbox = Checkbox(value=True, description='Agent', layout=Layout(width='20%'))\n",
        "\n",
        "# Function to update instruct selector\n",
        "def on_instruct_change(change):\n",
        "    global active_instruct\n",
        "    active_instruct = change['new']\n",
        "    update_display()\n",
        "\n",
        "# Dropdown for reasoning type\n",
        "instruct_selector = Dropdown(\n",
        "    options=[\"None\", \"Analysis\", \"Generation\",\"Mobility\"],\n",
        "    value=\"None\",\n",
        "    description='Reasoning:',\n",
        "    layout=Layout(width='50%')\n",
        ")\n",
        "instruct_selector.observe(on_instruct_change, names='value')\n",
        "\n",
        "# Dropdown for model selection\n",
        "model_selector = Dropdown(\n",
        "    options=[\"OpenAI\", \"DeepSeek\"],\n",
        "    value=\"OpenAI\",\n",
        "    description=\"Model:\",\n",
        "    layout=Layout(width=\"50%\")\n",
        ")\n",
        "\n",
        "# Display interactive widgets\n",
        "display(\n",
        "    VBox(\n",
        "        [user_selector, input_box, submit_button, agent_checkbox, tts_checkbox, files_checkbox, instruct_selector, model_selector],\n",
        "        layout=Layout(display='flex', flex_flow='column', align_items='flex-start', width='100%')\n",
        "    )\n",
        ")\n",
        "\n",
        "# Display reasoning output\n",
        "with reasoning_output:\n",
        "    reasoning_output.clear_output(wait=True)\n",
        "    print(\"Reasoning activated\")\n"
      ],
      "metadata": {
        "id": "MmQR8KvbRfwN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b43c9c1b2cf2429ca44773bc5124cf8f",
            "89fbe6c22fc347409a768bed2c70e858",
            "302464b059544d11915c8d2bd83176ac",
            "9485a729aeb9462c9ef91fd488a15b88",
            "539651c8eabb466ba68ccd5ee592ec07",
            "3e58eda3893d4e8b858eb9e048dfc34d",
            "1d7586b3e2334ec5b42d31c8996da352",
            "46ffe36735054d2ea528913118006f9a",
            "245479dfc48542e9a463b752c66c7441",
            "b1211ec6c94142cab077debf2d197a47",
            "83cb3bccc9b04e5098ef2b8876478227",
            "e85effd865b54e6c9d26d5b16ea6c441",
            "65913d1207d943b9ba10f46f9d0e7b1b",
            "8a6751de6ec74f6d932ad1bcb0596a16",
            "5235947249a148b486d50ff9d575650d",
            "dfd323a08338413381476987dbd294db",
            "a7dd68d0048d450fa4ef181c82306715",
            "885852eb967645aa952f32389257c36c",
            "2e59bff9307e4eee801da17f361492dd",
            "9cd5a8fda86642a9a2630a3cf32b7cde",
            "6f9a737debf74c528aa72b27fe6fb461",
            "8e849132ebd24af9af5ead1c8eca62bd",
            "0c1df8948ca14b86903e3ba2f58e1796",
            "efd3ec77daea4561970bfeaf8e6b1dec",
            "d82e2f26e2f140d284b96b2a3ff4bf5c",
            "8e1b09c19c814115b785beb120392c43",
            "2f8ba201d8714019a7bbf85c6e92c2cb",
            "78fea47e8f2d4084b7b4c84659476f40",
            "fb8ad19474294fa0b1998a3a6e9b13d0",
            "7dc80a2e370044f4a88f68a43febde13",
            "5cab07aaee9e45689a323f329dd4c733",
            "2f314036fdeb4064b10b2970ffad2746",
            "c57a0ef58fb643e0b8891564558f0fa4",
            "3952ea9839c442cdb1771ecf9e06f621",
            "da90a85d466a4e0c9c25c019e07be9e4",
            "d41bad43e25849008894226029e42916",
            "6e18b6d9eee340e8a9e24b32ac8bc7f4",
            "bbac8947472046749d090ee45102ccbe"
          ]
        },
        "outputId": "7250b04a-f827-4821-a447-21eb9bb42e1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**<span style='color: blue;'>User01:</span>** *Input Data:*<br><br>[<br>  (1, 50, 50, 75),<br>  (1, 51, 51, 76),<br>  (1, 52, 999, 999),<br>  (1, 53, 53, 78)<br>]<br><br>*Labels:*<br>LABELS: \"hour\", \"period\", \"aisle\", \"rack\""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**<span style='color: green;'>Agent:</span>** Process: the mobility agent is thinking<br><br><br>Customer message: {\"prediction\": [[1, 52, 52, 77]]}<br><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**<span style='color: blue;'>User01:</span>** *Input Data:*<br><br>[<br>  (1, 50, 50, 75),<br>  (1, 51, 51, 76),<br>  (1, 52, 999, 999),<br>  (1, 53, 53, 78)<br>]<br><br>*Labels:*<br>LABELS: \"hour\", \"period\", \"aisle\", \"rack\"  Once the output is given explain the labels in relation to the output"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**<span style='color: green;'>Agent:</span>** Process: the mobility agent is thinking<br><br><br>Customer message: {\"prediction\": [[1, 52, 52, 77]]}<br><br>**Explanation of Labels in Relation to the Output:**<br><br>- **hour:** This label corresponds to the `timeslot_id` in the data. Each `timeslot_id` represents a 30-minute interval within a 24-hour day. In the prediction, the `timeslot_id` is 52, which translates to the 26th hour of the day (since each timeslot is 30 minutes, timeslot 52 is the 26th half-hour, or 13th hour of the day).<br><br>- **period:** This label can be understood as a broader categorization of the time of day, such as morning, afternoon, evening, or night. In this context, the `timeslot_id` of 52 would likely fall into the afternoon or early evening period, depending on the specific time categorization used.<br><br>- **aisle:** This label corresponds to the `x` coordinate in the grid. In the prediction, the `x` coordinate is 52, indicating the specific \"aisle\" or column in the grid where the agent is located.<br><br>- **rack:** This label corresponds to the `y` coordinate in the grid. In the prediction, the `y` coordinate is 77, indicating the specific \"rack\" or row in the grid where the agent is located.<br><br>The prediction fills in the missing coordinates by estimating the most probable location based on the agent's movement pattern, ensuring continuity and consistency with the observed trajectory.<br><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**<span style='color: blue;'>User01:</span>** *Input Data:*<br><br>[<br>  (1, 50, 50, 75),<br>  (1, 51, 51, 76),<br>  (1, 52, 999, 999),<br>  (1, 53, 53, 78)<br>]<br><br>*Labels:*<br>LABELS: \"hour\", \"period\", \"aisle\", \"rack\" . Once the output is given explain the labels in relation to the output"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**<span style='color: green;'>Agent:</span>** Process: the mobility agent is thinking<br><br><br>Customer message: {\"prediction\": [[1, 52, 52, 77]]}<br><br>**Explanation of Labels in Relation to the Output:**<br><br>- **hour:** This label corresponds to the `timeslot_id` in the data. Each `timeslot_id` represents a 30-minute interval within a 24-hour day. In the prediction, the `timeslot_id` is 52, which translates to a specific hour and half-hour mark in the day.<br><br>- **period:** This label can be associated with the `day_id` and `timeslot_id` together, representing a specific period within the day. In the prediction, the period is defined by day 1 and timeslot 52, indicating a specific time frame on the first day.<br><br>- **aisle:** This label corresponds to the `x` coordinate in the grid. In the prediction, the `x` coordinate is 52, which can be thought of as the aisle number or position in the horizontal direction within the grid.<br><br>- **rack:** This label corresponds to the `y` coordinate in the grid. In the prediction, the `y` coordinate is 77, which can be thought of as the rack number or position in the vertical direction within the grid.<br><br>The prediction fills in the missing coordinates by estimating the most probable location based on the observed movement pattern, ensuring continuity and consistency with the agent's trajectory.<br><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Dropdown(description='User:', layout=Layout(width='50%'), options=('User01', 'User02', 'User03'…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e18b6d9eee340e8a9e24b32ac8bc7f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output(layout=Layout(border='1px solid black', margin='10px', padding='10px', width='100%'))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb8ad19474294fa0b1998a3a6e9b13d0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and display the conversation history"
      ],
      "metadata": {
        "id": "5hT4-GSS3Hez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from IPython.display import display, Markdown\n",
        "import os\n",
        "\n",
        "display_conversation_history=True\n",
        "summary=True\n",
        "\n",
        "if display_conversation_history == True or summary==True:\n",
        "    # File path\n",
        "    file_path = 'conversation_history.json'\n",
        "\n",
        "    # Check if the file exists\n",
        "    if os.path.exists(file_path):\n",
        "        print(f\"The file '{file_path}' exists.\")\n",
        "    else:\n",
        "        print(f\"The file '{file_path}' does not exist.\")\n",
        "        display_conversation_history=False\n",
        "        summary=False\n",
        "        print(\"Conversation history not processed\")"
      ],
      "metadata": {
        "id": "y8W1IpYdKyds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31443142-06d3-42bb-aa97-d823cf1390da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The file 'conversation_history.json' does not exist.\n",
            "Conversation history not processed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display option\n",
        "if display_conversation_history==True:\n",
        "  # File path\n",
        "  file_path = 'conversation_history.json'\n",
        "\n",
        "  # Open the file and read its content into the 'dialog' variable\n",
        "  with open(file_path, 'r', encoding='utf-8') as file:\n",
        "      dialog = json.load(file)  # Parse JSON content\n",
        "\n",
        "  # Function to format JSON content as markdown\n",
        "  def format_json_as_markdown(data, level=0):\n",
        "      html_output = \"\"\n",
        "      indent = \"  \" * level\n",
        "      if isinstance(data, dict):\n",
        "          for key, value in data.items():\n",
        "              html_output += f\"{indent}**{key}**:<br>\\n\"\n",
        "              html_output += format_json_as_markdown(value, level + 1)\n",
        "      elif isinstance(data, list):\n",
        "          for item in data:\n",
        "              html_output += format_json_as_markdown(item, level)\n",
        "      else:\n",
        "          html_output += f\"{indent}{data}<br>\\n\"\n",
        "      return html_output\n",
        "\n",
        "  # Format the JSON into markdown\n",
        "  formatted_markdown = format_json_as_markdown(dialog)\n",
        "\n",
        "  # Display formatted JSON as Markdown\n",
        "  display(Markdown(formatted_markdown))"
      ],
      "metadata": {
        "id": "OcPwASR3cuSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and summarize the conversation history"
      ],
      "metadata": {
        "id": "S2co30FUEhK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "def summarize_conversation(file_path):\n",
        "    \"\"\"\n",
        "    Reads a conversation history JSON file, formats it, and generates a detailed\n",
        "    summary with a list of actions from the JSON text. The summary is displayed in Markdown.\n",
        "\n",
        "    Parameters:\n",
        "        file_path (str): Path to the JSON file containing conversation history.\n",
        "\n",
        "    Returns:\n",
        "        None: The summary is displayed as Markdown output.\n",
        "    \"\"\"\n",
        "    # Step 1: Read the conversation history from the JSON file\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        dialog = file.read()\n",
        "    conversation_history_json = json.loads(dialog)\n",
        "\n",
        "    # Step 2: Construct dialog string from the JSON conversation history\n",
        "    def construct_dialog(conversation_history_json):\n",
        "        dialog = \"\"\n",
        "        for user, messages in conversation_history_json.items():\n",
        "            dialog += f\"\\n{user}:\\n\"\n",
        "            for message in messages:\n",
        "                role = message[\"role\"]\n",
        "                content = message[\"content\"]\n",
        "                dialog += f\"- {role}: {content}\\n\"\n",
        "        return dialog\n",
        "\n",
        "    formatted_dialog = construct_dialog(conversation_history_json)\n",
        "\n",
        "    # Step 3: Prepare the task for the summary\n",
        "    mrole = \"system\"\n",
        "    mcontent = \"Your task is to read this JSON formatted text and summarize it.\"\n",
        "    user_role = \"user\"\n",
        "    task = f\"Read this JSON formatted text and make a very detailed summary of it with a list of actions:\\n{formatted_dialog}\"\n",
        "\n",
        "    # Step 4: Call the `make_openai_api_call` function\n",
        "    task_response = make_openai_api_call(task, mrole, mcontent, user_role)\n",
        "\n",
        "    # Step 5: Display the task response as Markdown\n",
        "    display(Markdown(task_response))\n"
      ],
      "metadata": {
        "id": "EEzhcMaMFYVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if summary==True:\n",
        "    # File path to the JSON file\n",
        "    file_path = '/content/conversation_history.json'\n",
        "\n",
        "    # Check if the file exists before calling the function\n",
        "    if os.path.exists(file_path):\n",
        "        summarize_conversation(file_path)\n",
        "    else:\n",
        "        print(f\"File '{file_path}' does not exist. Please provide a valid file path.\")\n"
      ],
      "metadata": {
        "id": "S6iA-jOUj8s-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}