{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNc9+Lv650yaPi6sDm+BavB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ad1eb9afde334f508075d30b9af67690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d57bb435157426d929af5e17ff7bd3f",
              "IPY_MODEL_64a1b1e870954c46ab0150bf0e95550b",
              "IPY_MODEL_629c04479d7247149ac8d9ae6e1d8a47"
            ],
            "layout": "IPY_MODEL_fa0a6f27843e40ce9ee4e5bcd475c1f8"
          }
        },
        "8d57bb435157426d929af5e17ff7bd3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "User01",
              "User02",
              "User03"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "User:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_8b8d032e3f8f4d5aac0a6f63927d2fab",
            "style": "IPY_MODEL_2d071a7425b149748a0699d517b1bfbe"
          }
        },
        "64a1b1e870954c46ab0150bf0e95550b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_5218043cc3e74a93a0e53e5d350ea858",
            "placeholder": "Type your message here or type 'exit' or 'quit' to end the conversation.",
            "style": "IPY_MODEL_fdf3ead3294141828a43ff303c778b08",
            "value": ""
          }
        },
        "629c04479d7247149ac8d9ae6e1d8a47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Agent",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_221e2706be764e27b69f5fa6397e496b",
            "style": "IPY_MODEL_63bef18836814b4b93367fb7326260ae",
            "value": true
          }
        },
        "fa0a6f27843e40ce9ee4e5bcd475c1f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "flex-start",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "8b8d032e3f8f4d5aac0a6f63927d2fab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "2d071a7425b149748a0699d517b1bfbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5218043cc3e74a93a0e53e5d350ea858": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "fdf3ead3294141828a43ff303c778b08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "221e2706be764e27b69f5fa6397e496b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20%"
          }
        },
        "63bef18836814b4b93367fb7326260ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eaf712e0885c4c3685389b99742d8439": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d57bb435157426d929af5e17ff7bd3f",
              "IPY_MODEL_64a1b1e870954c46ab0150bf0e95550b",
              "IPY_MODEL_629c04479d7247149ac8d9ae6e1d8a47"
            ],
            "layout": "IPY_MODEL_50836193111f498583be78be71560b72"
          }
        },
        "50836193111f498583be78be71560b72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11f52f517a794124ad79c8ebec245c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d57bb435157426d929af5e17ff7bd3f",
              "IPY_MODEL_64a1b1e870954c46ab0150bf0e95550b",
              "IPY_MODEL_629c04479d7247149ac8d9ae6e1d8a47"
            ],
            "layout": "IPY_MODEL_3c09fd99ead8434b9840f994c05383d5"
          }
        },
        "3c09fd99ead8434b9840f994c05383d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Business-ready GenAISys framework\n",
        "\n",
        "copyright 2025, Denis Rothman\n",
        "\n",
        "As Generative AI spreads through hundreds of activities worldwide, the need for custom business-driven ChatGPT-like Generative AI Systems(GenAISys) is increasing.\n",
        "\n",
        "This notebook introduces a framework for a custom GenAISys for a business. The features take the system beyond public platforms into the real world of business constraints. As such, the framework includes:\n",
        "\n",
        "*  Multi-user dialogs in an interface between users with or without a GPT-4o GenAI agent.\n",
        "*  Multi-user dialogs with a GPT-4o GenAI agent\n",
        "*  Interactions with a Pinecone vector store that contains a repository of instructions for the GenAI that will be triggered in real-time\n",
        "* Interactions with a Pinecone vector store to retrieve episodic memories from a business. In this case, stored messages from a CTO that only the organization can know about.\n",
        "*  Interactions with the users without a GenAI being involved.\n",
        "*  An automated conversation log function that can also be leveraged to automatically generate the summary and action plan of an online multi-user meeting with a GenAI as a participant.\n",
        "\n",
        "**Notebook summary**\n",
        "\n",
        "1. Installing OpenAI and customer OpenAI GPT-4o calls.\n",
        "2. Installing Pinecone and connecting to the Pinecone Index\n",
        "3. Pinecone vector store querying functions\n",
        "4. A conversational agent\n",
        "5. A multi-user interface with the AI agent as a participant.\n",
        "6. Loading and displaying the conversation when it is over\n",
        "7. Summarizing and displaying the summary of the meeting.\n",
        "\n",
        "\n",
        "**Note**: *This notebook is for educational purposes only. It is not designed to be deployed into production.\n",
        "The notebook implements an educational dialog to verify the functions developed in the previous chapters and integrated in the multi-user interface of this notebook*\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rA2_SNjzA4Dc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up the environment"
      ],
      "metadata": {
        "id": "vub82Rjxa17a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## File downloading script\n",
        "\n",
        "grequests contains a script to download files from the repository"
      ],
      "metadata": {
        "id": "S8_G2ePO11rQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Private repository notes\n",
        "#1.This line will be deleted when the repository is made public and the following line will be uncommented\n",
        "#2.The private token will also be removed from grequests.py in the commmons directory of the repository\n",
        "!curl -L -H \"Authorization: Bearer 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\" https://raw.githubusercontent.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/master/commons/grequests.py --output grequests.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4_26Hfdx2kX",
        "outputId": "35ea85df-31f1-4634-8df0-1c9f04562c80"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1008  100  1008    0     0   2706      0 --:--:-- --:--:-- --:--:--  2709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!curl -L https://raw.githubusercontent.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/master/commons/grequests.py --output grequests.py"
      ],
      "metadata": {
        "id": "vzkCTNNChWAJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI"
      ],
      "metadata": {
        "id": "jmmBBZ7oa17b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from grequests import download\n",
        "download(\"commons\",\"requirements01.py\")\n",
        "download(\"commons\",\"openai_setup.py\")\n",
        "download(\"commons\",\"openai_api.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e928553-e2af-498b-9c67-4957a1993d44",
        "id": "G_PuE5rjhWAK"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 'requirements01.py' successfully.\n",
            "Downloaded 'openai_setup.py' successfully.\n",
            "Downloaded 'openai_api.py' successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing OpenAI"
      ],
      "metadata": {
        "id": "9kNLfjTfAnFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the setup script to install and import dependencies\n",
        "%run requirements01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7i8j5vnpatH",
        "outputId": "3fa2daf3-450b-4035-b205-d61ddd9ec73f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uninstalling 'openai'...\n",
            "Installing 'openai' version 1.57.1...\n",
            "'openai' version 1.57.1 is installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initializing the OpenAI API key\n",
        "\n"
      ],
      "metadata": {
        "id": "O03SZzGGAreV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "google_secrets=True #activates Google secrets in Google Colab\n",
        "if google_secrets==True:\n",
        "  import openai_setup\n",
        "  openai_setup.initialize_openai_api()"
      ],
      "metadata": {
        "id": "pDn09vPbAXPT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "531b931e-e590-4792-f13e-91089f60f40f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API key initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if google_secrets==False: # Uncomment the code and choose any method you wish to initialize the API_KEY\n",
        "  import os\n",
        "  #API_KEY=[YOUR API_KEY]\n",
        "  #os.environ['OPENAI_API_KEY'] = API_KEY\n",
        "  #openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "  #print(\"OpenAI API key initialized successfully.\")"
      ],
      "metadata": {
        "id": "C3398f_cetsD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NL93eSL-mLi"
      },
      "source": [
        "#### Importing the API call function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the function from the custom OpenAI API file\n",
        "import openai_api\n",
        "from openai_api import make_openai_api_call"
      ],
      "metadata": {
        "id": "0lMhv09G0kzr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QGI1D8FVrT6"
      },
      "source": [
        "## Installing Pinecone"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download(\"commons\",\"requirements02.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3ufJsT54EHe",
        "outputId": "6bdc99d6-ae53-48a2-96b9-54b3f26dc591"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 'requirements02.py' successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Z2abuU9OkVFL",
        "outputId": "c79137bf-33b6-4168-8208-15793718c77b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uninstalling 'pinecone-client'...\n",
            "Installing 'pinecone-client' version 5.0.1...\n",
            "'pinecone-client' version 5.0.1 is installed.\n"
          ]
        }
      ],
      "source": [
        "# Run the setup script to install and import dependencies\n",
        "%run requirements02"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializing the Pinecone API key"
      ],
      "metadata": {
        "id": "tum9Jd1odcNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "download(\"commons\",\"pinecone_setup.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eIyjdd25LjH",
        "outputId": "e5f7ca33-90e7-4eb3-ea52-f98d92f270aa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 'pinecone_setup.py' successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if google_secrets==True:\n",
        "  import pinecone_setup\n",
        "  pinecone_setup.initialize_pinecone_api()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zPS_mgsdXKj",
        "outputId": "348121dd-3760-4fae-aaf3-e6a0ad82547b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PINECONE_API_KEY initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if google_secrets==False: # Uncomment the code and choose any method you wish to initialize the Pinecone API key\n",
        "  import os\n",
        "  #PINECONE_API_KEY=[YOUR PINECONE_API_KEY]\n",
        "  #os.environ['PINECONE_API_KEY'] = PINECONE_API_KEY\n",
        "  #openai.api_key = os.getenv(\"PINECONE_API_KEY\")\n",
        "  #print(\"OpenAI API key initialized successfully.\")"
      ],
      "metadata": {
        "id": "D-dJTlEn_FZZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XswfiN5Z1OvT"
      },
      "source": [
        "#  The Pinecone index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "# Retrieve the API key from environment variables\n",
        "api_key = os.environ.get('PINECONE_API_KEY')\n",
        "if not api_key:\n",
        "    raise ValueError(\"PINECONE_API_KEY is not set in the environment!\")\n",
        "\n",
        "# Initialize the Pinecone client\n",
        "pc = Pinecone(api_key=api_key)"
      ],
      "metadata": {
        "id": "cKCvBbZPTIjH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "P---PNLpXeQs"
      },
      "outputs": [],
      "source": [
        "from pinecone import ServerlessSpec\n",
        "\n",
        "index_name = 'genai-v1'\n",
        "cloud = os.environ.get('PINECONE_CLOUD') or 'aws'\n",
        "region = os.environ.get('PINECONE_REGION') or 'us-east-1'\n",
        "\n",
        "spec = ServerlessSpec(cloud=cloud, region=region)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO7AYljM0gq1",
        "outputId": "5cc59009-8b93-4566-dbf9-b760474eb1a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {'data01': {'vector_count': 9}, 'genaisys': {'vector_count': 3}},\n",
              " 'total_vector_count': 12}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "import time\n",
        "import pinecone\n",
        "# check if index already exists (it shouldn't if this is first time)\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    # if does not exist, create index\n",
        "    pc.create_index(\n",
        "        index_name,\n",
        "        dimension=1536,  # dimension of the embedding model\n",
        "        metric='cosine',\n",
        "        spec=spec\n",
        "    )\n",
        "    # wait for index to be initialized\n",
        "    time.sleep(1)\n",
        "\n",
        "# connect to index\n",
        "index = pc.Index(index_name)\n",
        "# view index stats\n",
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Querying functions"
      ],
      "metadata": {
        "id": "9iIIeZB7RUDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_results(query_results):\n",
        "  for match in query_results['matches']:\n",
        "    print(f\"ID: {match['id']}, Score: {match['score']}\")\n",
        "    if 'metadata' in match and 'text' in match['metadata']:\n",
        "        text=match['metadata']['text']\n",
        "        #print(f\"Text: {match['metadata']['text']}\")\n",
        "        target_id = query_results['matches'][0]['id']  # Get the ID from the first match\n",
        "                #print(f\"Target ID: {target_id}\")\n",
        "    else:\n",
        "        print(\"No metadata available.\")\n",
        "  return text, target_id\n"
      ],
      "metadata": {
        "id": "NS2HWdO76iQh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "DT6wytGz5hTS"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "client = openai.OpenAI()\n",
        "embedding_model = \"text-embedding-3-small\"\n",
        "def get_embedding(text, model=embedding_model):\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    response = client.embeddings.create(input=[text], model=model)\n",
        "    embedding = response.data[0].embedding\n",
        "    return embedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_query_results(query_text, namespace):\n",
        "    # Generate the query vector from the query text\n",
        "    query_vector = get_embedding(query_text)  # Replace with your method to generate embeddings\n",
        "\n",
        "    # Perform the query\n",
        "    query_results = index.query(\n",
        "        vector=query_vector,\n",
        "        namespace=namespace,\n",
        "        top_k=1,  # Adjust as needed\n",
        "        include_metadata=True\n",
        "    )\n",
        "    # Return the results\n",
        "    return query_results"
      ],
      "metadata": {
        "id": "_FxS2Q0nnZAq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_vector_store(query_text, namespace):\n",
        "    print(\"Querying vector store...\")\n",
        "\n",
        "    # Retrieve query results\n",
        "    query_results = get_query_results(query_text, namespace)\n",
        "\n",
        "    # Process and display the results\n",
        "    print(\"Processed query results:\")\n",
        "    text, target_id = display_results(query_results)\n",
        "\n",
        "    return text, target_id"
      ],
      "metadata": {
        "id": "-k5GxQGZSjlY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conversational agent"
      ],
      "metadata": {
        "id": "VesAR25Ywxcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "\n",
        "# Initialize the OpenAI client\n",
        "client = OpenAI()\n",
        "user_memory=True # True=User messages are memorized False=User messages are not memorized\n",
        "def chat_with_gpt(messages, user_message):\n",
        "    try:\n",
        "      namespace=\"\"\n",
        "      if \"Pinecone\" in user_message or \"RAG\" in user_message:\n",
        "         # Determine the keyword\n",
        "        if \"Pinecone\" in user_message:\n",
        "            namespace=\"genaisys\"\n",
        "        elif \"RAG\" in user_message:\n",
        "            namespace=\"data01\"\n",
        "        print(namespace)\n",
        "        #define query text\n",
        "        query_text=user_message\n",
        "        # Retrieve query results\n",
        "        query_results = get_query_results(query_text, namespace)\n",
        "        # Process and display the results\n",
        "        print(\"Processed query results:\")\n",
        "        qtext, target_id = display_results(query_results)\n",
        "        print(qtext)\n",
        "        #run task\n",
        "        sc_input=qtext + \" \" + user_message\n",
        "        mrole = \"system\"\n",
        "        mcontent = \"You are an assistant executes the tasks you are asked to do.\"\n",
        "        user_role = \"user\"\n",
        "        task_response = openai_api.make_openai_api_call(sc_input,mrole,mcontent,user_role)\n",
        "        print(task_response)\n",
        "        aug_output=namespace + \":\" +task_response\n",
        "      else:\n",
        "        if user_memory==True:\n",
        "          umessage=messages + \" \" +user_message\n",
        "        else:\n",
        "          umessage=user_message\n",
        "        mrole = \"system\"\n",
        "        mcontent = \"You are an assistant executes the tasks you are asked to do.\"\n",
        "        user_role = \"user\"\n",
        "        task_response = openai_api.make_openai_api_call(umessage,mrole,mcontent,user_role)\n",
        "        aug_output=task_response\n",
        "\n",
        "      # Return the augmented output\n",
        "      return aug_output\n",
        "\n",
        "    except Exception as e:\n",
        "        # Return the error message in case of an exception\n",
        "        return f\"An error occurred: {str(e)}\""
      ],
      "metadata": {
        "id": "PEz84qfqs-0g"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GenAISys IPYthon interface\n",
        "\n",
        "**Note**: *This is an educational dialog to verify the functions developed in the previous chapters and integrated in the multi-user interface of this notebook*\n",
        "\n",
        "**Example of a multi-user session**\n",
        "\n",
        "Enter the following scenario to verify the system and then experiment to see its scope and limits.\n",
        "\n",
        "Make sure the `agent` checkbox option is checked to activate the generative AI model.\n",
        "\n",
        "Prompt 1-`user01`, to verify task orchestration for semantic analysis.\n",
        "The keyword `Pinecone` will trigger similarity search for task instructions.\n",
        "\n",
        "`A customer said that our travel agency was pretty good but should have more activities. Let's ask Pinecone for ideas. `\n",
        "\n",
        "Prompt 2-`user02` to verify task orchestration for sentiment analysis.\n",
        "The keyword `Pinecone` will trigger similarity search for task instructions.\n",
        "\n",
        "`A customer said that our travel agency was worse than our competition and should have better service. Let's ask Pinecone what its sentiment is.`\n",
        "\n",
        "Prompt 3-`user03` to verify task orchestration for RAG.   \n",
        "The keyword `RAG` will trigger similarity search for data retrieval.   \n",
        "`The CTO was talking about leveraging different kind of memories the other day. What did he mean by that? Let's search RAG.`\n",
        "\n",
        "Prompt 4-`user01`to verify task orchestration without RAG.   \n",
        "`But what you, the AI Agent, suggest we do to leverage these types of memories in are travelling promotion campaigns?`\n",
        "\n",
        "Prompt 6- `user01` unchecks the `agent` checkbox to deactivate the generative AI and just text the other users.\n",
        "\n",
        "`OK. Let's stop here, get a summary and go see the manager to get some green lights to move ahead.`"
      ],
      "metadata": {
        "id": "VQdrOoyZxblG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML, clear_output\n",
        "from ipywidgets import Dropdown, Text, Checkbox, VBox, Layout\n",
        "import json\n",
        "\n",
        "# Initialize conversation histories for all users and active user\n",
        "user_histories = {\"User01\": [], \"User02\": [], \"User03\": []}\n",
        "active_user = \"User01\"  # Default user\n",
        "conversation_active = True\n",
        "\n",
        "# Function to handle user input and optional bot response\n",
        "def chat(user_message):\n",
        "    global conversation_active\n",
        "    # Check for exit signal\n",
        "    if user_message.lower() in ['exit', 'quit']:\n",
        "        conversation_active = False\n",
        "        clear_output(wait=True)\n",
        "        display(HTML(\"<div style='color: red;'><strong>Conversation ended. Saving history...</strong></div>\"))\n",
        "        save_conversation_history()  # Save the conversation history to a file\n",
        "        display(HTML(\"<div style='color: green;'><strong>History saved. Proceed to the next cell.</strong></div>\"))\n",
        "        return\n",
        "\n",
        "    # Append user message to the active user's history\n",
        "    user_histories[active_user].append({\"role\": \"user\", \"content\": user_message})\n",
        "\n",
        "    # Generate bot response if agent_checkbox is checked\n",
        "    if agent_checkbox.value:\n",
        "        response = chat_with_gpt(user_histories[active_user], user_message)\n",
        "        # Append bot response to the active user's history\n",
        "        user_histories[active_user].append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "    # Update display\n",
        "    update_display()\n",
        "\n",
        "# Function to update the display\n",
        "def update_display():\n",
        "    clear_output(wait=True)\n",
        "    for entry in user_histories[active_user]:  # Show only the active user's history\n",
        "        if entry['role'] == 'user':\n",
        "            display(HTML(f\"<div style='text-align: left; margin-left: 20px; color: blue;'><strong>{active_user}:</strong> {entry['content']}</div>\"))\n",
        "        elif entry['role'] == 'assistant':\n",
        "            display(HTML(f\"<div style='text-align: left; margin-left: 20px; color: green;'><strong>Agent:</strong> {entry['content']}</div>\"))\n",
        "    if conversation_active:\n",
        "        display(VBox([user_selector, input_box, agent_checkbox]))  # Keep input box, selector, and checkbox visible if active\n",
        "\n",
        "# Function to handle the submission of the input\n",
        "def handle_submit(sender):\n",
        "    user_message = sender.value\n",
        "    if user_message.strip():\n",
        "        sender.value = \"\"  # Clear the input box\n",
        "        chat(user_message)\n",
        "\n",
        "# Function to update the active user\n",
        "def on_user_change(change):\n",
        "    global active_user\n",
        "    active_user = change['new']\n",
        "    update_display()  # Update the display to show the new active user's history\n",
        "\n",
        "# Function to save conversation history to a file\n",
        "def save_conversation_history():\n",
        "    filename = \"conversation_history.json\"  # Define the filename\n",
        "    with open(filename, 'w') as file:\n",
        "        json.dump(user_histories, file, indent=4)  # Write the user histories dictionary to the file in JSON format\n",
        "    display(HTML(f\"<div style='color: green;'><strong>Conversation history saved to {filename}.</strong></div>\"))\n",
        "\n",
        "# Create a dropdown to select the user\n",
        "user_selector = Dropdown(\n",
        "    options=[\"User01\", \"User02\", \"User03\"],\n",
        "    value=active_user,\n",
        "    description='User:',\n",
        "    layout=Layout(width='50%')\n",
        ")\n",
        "user_selector.observe(on_user_change, names='value')\n",
        "\n",
        "# Create the input box widget\n",
        "input_box = Text(placeholder=\"Type your message here or type 'exit' or 'quit' to end the conversation.\", layout=Layout(width='100%'))\n",
        "input_box.on_submit(handle_submit)  # Attach the on_submit event handler\n",
        "\n",
        "# Create a checkbox to toggle agent response\n",
        "agent_checkbox = Checkbox(\n",
        "    value=True,\n",
        "    description='Agent',\n",
        "    layout=Layout(width='20%')\n",
        ")\n",
        "\n",
        "# Display the initial interface\n",
        "display(VBox([user_selector, input_box, agent_checkbox], layout=Layout(display='flex', flex_flow='column', align_items='flex-start', width='100%')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199,
          "referenced_widgets": [
            "ad1eb9afde334f508075d30b9af67690",
            "8d57bb435157426d929af5e17ff7bd3f",
            "64a1b1e870954c46ab0150bf0e95550b",
            "629c04479d7247149ac8d9ae6e1d8a47",
            "fa0a6f27843e40ce9ee4e5bcd475c1f8",
            "8b8d032e3f8f4d5aac0a6f63927d2fab",
            "2d071a7425b149748a0699d517b1bfbe",
            "5218043cc3e74a93a0e53e5d350ea858",
            "fdf3ead3294141828a43ff303c778b08",
            "221e2706be764e27b69f5fa6397e496b",
            "63bef18836814b4b93367fb7326260ae",
            "eaf712e0885c4c3685389b99742d8439",
            "50836193111f498583be78be71560b72",
            "11f52f517a794124ad79c8ebec245c86",
            "3c09fd99ead8434b9840f994c05383d5"
          ]
        },
        "id": "iWtVpvQwGf_4",
        "outputId": "c1a72bb1-8ea1-4572-bb29-123180c3e7b2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='text-align: left; margin-left: 20px; color: blue;'><strong>User01:</strong> What is the capital of France?</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='text-align: left; margin-left: 20px; color: green;'><strong>Agent:</strong> The capital of France is Paris.</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='text-align: left; margin-left: 20px; color: blue;'><strong>User01:</strong> What is there to visit there?</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='text-align: left; margin-left: 20px; color: green;'><strong>Agent:</strong> I'm happy to help, but I'll need a bit more information to provide a useful answer. Could you please specify the location or area you're interested in visiting?</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Dropdown(description='User:', layout=Layout(width='50%'), options=('User01', 'User02', 'User03'…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11f52f517a794124ad79c8ebec245c86"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and display conversation"
      ],
      "metadata": {
        "id": "5hT4-GSS3Hez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and summarize conversation"
      ],
      "metadata": {
        "id": "S2co30FUEhK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# File path\n",
        "file_path = 'conversation_history.json'\n",
        "\n",
        "# Open the file and read its content into the 'dialog' variable\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    dialog = file.read()\n",
        "\n",
        "# Now the content of the file is stored in 'dialog'\n",
        "print(dialog)  # Optional: Display the content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxnClt5yEkCx",
        "outputId": "9f7ba140-0c28-4c72-812d-0e9a078c42c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"User01\": [\n",
            "        {\n",
            "            \"role\": \"user\",\n",
            "            \"content\": \"A customer said that our travel agency was pretty good but should have more activities. Let's ask Pinecone for ideas.\"\n",
            "        },\n",
            "        {\n",
            "            \"role\": \"assistant\",\n",
            "            \"content\": \"genaisys:To enhance your travel agency's offerings based on the customer's feedback, you can use semantic search to gather ideas and insights. Semantic search goes beyond keyword matching and understands the context and intent behind the search queries, which can be particularly useful for generating creative and relevant ideas.\\n\\nHere's how you can approach this:\\n\\n1. **Identify Key Themes**: Start by identifying key themes or categories of activities that are popular or trending in the travel industry. This could include adventure activities, cultural experiences, wellness retreats, culinary tours, etc.\\n\\n2. **Use Pinecone for Semantic Search**: Pinecone is a vector database that can be used to perform semantic searches. You can input descriptions or keywords related to travel activities and use Pinecone to find similar or related concepts. This can help you discover new activities that align with your current offerings or explore entirely new categories.\\n\\n3. **Analyze Competitor Offerings**: Use semantic search to analyze what activities competitors are offering. This can provide insights into gaps in your current offerings and inspire new ideas.\\n\\n4. **Customer Feedback Analysis**: Use semantic analysis on customer reviews and feedback to identify specific activities that customers have enjoyed or requested. This can help tailor your offerings to meet customer expectations.\\n\\n5. **Trend Analysis**: Look for emerging trends in travel activities using semantic search. This can include eco-friendly travel, digital detox retreats, or virtual reality experiences. Staying ahead of trends can give your agency a competitive edge.\\n\\n6. **Collaborate with Local Experts**: Use semantic search to find local experts or businesses that offer unique activities. Partnering with them can enhance your activity offerings and provide authentic experiences to your customers.\\n\\n7. **Personalization**: Use the insights gained from semantic search to personalize travel packages. Offer customizable itineraries that allow customers to choose from a variety of activities based on their interests.\\n\\nBy leveraging semantic search with tools like Pinecone, you can gain a deeper understanding of potential activities to offer, ensuring they align with customer interests and industry trends. This approach can help your travel agency stand out by providing a diverse and appealing range of activities.\"\n",
            "        },\n",
            "        {\n",
            "            \"role\": \"user\",\n",
            "            \"content\": \"But what you, the AI Agent, suggest we do to leverage these types of memories in are travelling promotion campaigns?\"\n",
            "        },\n",
            "        {\n",
            "            \"role\": \"assistant\",\n",
            "            \"content\": \"To effectively leverage memories in your travel promotion campaigns, consider the following strategies:\\n\\n1. **Storytelling**: Use storytelling to evoke emotions and create a narrative that potential travelers can relate to. Share stories of past travelers, highlighting memorable experiences and unique moments that they cherished.\\n\\n2. **User-Generated Content**: Encourage past travelers to share their photos, videos, and stories on social media. Create a campaign hashtag and feature the best content on your platforms. This not only provides authentic content but also builds a community around shared experiences.\\n\\n3. **Nostalgia Marketing**: Tap into nostalgia by highlighting destinations or experiences that evoke fond memories. This could be through retro-themed campaigns or by showcasing how a destination has retained its charm over the years.\\n\\n4. **Personalization**: Use data to personalize marketing messages. Tailor recommendations based on past travel behaviors or preferences, making the potential traveler feel understood and valued.\\n\\n5. **Immersive Experiences**: Utilize virtual reality (VR) or augmented reality (AR) to give potential travelers a taste of the experiences they can have. This can create a memorable pre-travel experience that encourages them to book a trip.\\n\\n6. **Emotional Appeal**: Focus on the emotional benefits of travel, such as relaxation, adventure, or connection with loved ones. Use imagery and language that evoke these feelings, making the potential traveler imagine the memories they could create.\\n\\n7. **Influencer Collaborations**: Partner with influencers who can share their personal travel memories and experiences with their audience. Their authentic stories can inspire their followers to create their own memories by traveling.\\n\\n8. **Memory-Making Packages**: Offer special travel packages designed around creating memorable experiences, such as romantic getaways, family adventures, or cultural immersions. Highlight the unique aspects that make these packages memorable.\\n\\n9. **Testimonials and Reviews**: Feature testimonials and reviews from past travelers that emphasize the memorable aspects of their trips. This social proof can be persuasive for potential travelers.\\n\\n10. **Interactive Campaigns**: Create interactive campaigns that engage potential travelers, such as quizzes or polls about their dream travel experiences. This can help them visualize the memories they want to create.\\n\\nBy focusing on the emotional and experiential aspects of travel, you can create compelling campaigns that resonate with potential travelers and inspire them to embark on their own memory-making journeys.\"\n",
            "        },\n",
            "        {\n",
            "            \"role\": \"user\",\n",
            "            \"content\": \"OK. Let's stop here, get a summary and go see the manager to get some green lights to move ahead.\"\n",
            "        }\n",
            "    ],\n",
            "    \"User02\": [\n",
            "        {\n",
            "            \"role\": \"user\",\n",
            "            \"content\": \"A customer said that our travel agency was worse than our competition and should have better service. Let's ask Pinecone what its sentiment is.\"\n",
            "        },\n",
            "        {\n",
            "            \"role\": \"assistant\",\n",
            "            \"content\": \"genaisys:Sentiment analysis score: 0.2\\n\\nExplanation: The text expresses a negative sentiment towards the travel agency. The customer compares the agency unfavorably to its competition and suggests that the service should be improved. Words like \\\"worse\\\" and \\\"should have better service\\\" indicate dissatisfaction, leading to a low sentiment score.\"\n",
            "        }\n",
            "    ],\n",
            "    \"User03\": [\n",
            "        {\n",
            "            \"role\": \"user\",\n",
            "            \"content\": \"The CTO was talking about leveraging different kind of memories the other day. What did he mean by that? Let's search RAG.\"\n",
            "        },\n",
            "        {\n",
            "            \"role\": \"assistant\",\n",
            "            \"content\": \"data01:In the context of Retrieval-Augmented Generation (RAG) and AI systems, leveraging different kinds of memories typically refers to the use of various memory mechanisms to enhance the AI's ability to store, retrieve, and utilize information effectively. Here are some types of memories that might be relevant:\\n\\n1. **Short-term Memory**: This is used to store information temporarily while the AI is processing a task. It allows the AI to keep track of the current context and make decisions based on recent inputs.\\n\\n2. **Long-term Memory**: This involves storing information over a longer period, allowing the AI to retain knowledge and experiences that can be used in future tasks. This can include facts, learned patterns, and historical data.\\n\\n3. **Episodic Memory**: This type of memory is used to store specific events or experiences, allowing the AI to recall past interactions or scenarios. It can be useful for personalizing responses or adapting to user preferences.\\n\\n4. **Semantic Memory**: This involves storing general knowledge about the world, such as facts, concepts, and relationships. It enables the AI to understand and reason about the information it encounters.\\n\\n5. **Procedural Memory**: This is related to storing information about how to perform tasks or procedures. It allows the AI to execute complex sequences of actions based on learned skills or instructions.\\n\\n6. **External Memory**: In some systems, external databases or knowledge bases are used as a form of memory, allowing the AI to access vast amounts of information that are not stored internally.\\n\\nBy leveraging these different types of memories, an AI system can become more versatile and capable of handling a wide range of tasks and scenarios. In the context of RAG, these memory mechanisms can be orchestrated to dynamically retrieve and apply relevant information, enhancing the AI's performance and adaptability.\"\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mrole = \"system\"\n",
        "mcontent = \"Your task is to read this json formatted text and summarize it.\"\n",
        "user_role = \"user\"\n",
        "task=\"Read this json formatted text and make a very detailled summary of it with a list actions:\"+ dialog\n",
        "task_response = openai_api.make_openai_api_call(task,mrole,mcontent,user_role)"
      ],
      "metadata": {
        "id": "2P_siIn7Ey0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display\n",
        "# Display the task response as Markdown\n",
        "display(Markdown(task_response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 954
        },
        "id": "-c_DUElFFehV",
        "outputId": "074d2115-f264-4f95-90c9-a03ae170058c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The JSON text contains interactions between users and an AI assistant, focusing on improving a travel agency's offerings and understanding customer feedback. Here's a detailed summary with a list of actions:\n\n### User01 Interactions:\n1. **Feedback on Travel Agency**: A customer suggested that the travel agency is good but could benefit from more activities.\n2. **Assistant's Suggestions**:\n   - **Semantic Search**: Use Pinecone, a vector database, for semantic search to enhance travel offerings.\n     - **Identify Key Themes**: Focus on popular travel activity categories like adventure, culture, wellness, etc.\n     - **Analyze Competitor Offerings**: Use semantic search to find gaps and inspire new ideas.\n     - **Customer Feedback Analysis**: Identify activities customers enjoy or request.\n     - **Trend Analysis**: Discover emerging trends like eco-friendly travel or VR experiences.\n     - **Collaborate with Local Experts**: Partner with local businesses for unique activities.\n     - **Personalization**: Offer customizable itineraries based on customer interests.\n3. **Leveraging Memories in Promotions**:\n   - **Storytelling**: Share relatable travel stories.\n   - **User-Generated Content**: Encourage sharing of travel experiences on social media.\n   - **Nostalgia Marketing**: Highlight destinations with nostalgic value.\n   - **Personalization**: Tailor marketing messages using data.\n   - **Immersive Experiences**: Use VR/AR for pre-travel experiences.\n   - **Emotional Appeal**: Focus on emotional benefits of travel.\n   - **Influencer Collaborations**: Partner with influencers for authentic stories.\n   - **Memory-Making Packages**: Offer packages designed for memorable experiences.\n   - **Testimonials and Reviews**: Use social proof to persuade potential travelers.\n   - **Interactive Campaigns**: Engage potential travelers with quizzes or polls.\n\n### User02 Interactions:\n1. **Negative Customer Feedback**: A customer compared the agency unfavorably to competitors, suggesting service improvements.\n2. **Sentiment Analysis**:\n   - **Score**: 0.2, indicating negative sentiment.\n   - **Explanation**: Words like \"worse\" and \"should have better service\" reflect dissatisfaction.\n\n### User03 Interactions:\n1. **Understanding Memory in AI**: Inquiry about leveraging different kinds of memories.\n2. **Assistant's Explanation**:\n   - **Short-term Memory**: Temporary storage for current tasks.\n   - **Long-term Memory**: Retains knowledge for future use.\n   - **Episodic Memory**: Stores specific events for personalized responses.\n   - **Semantic Memory**: General world knowledge for reasoning.\n   - **Procedural Memory**: Information on performing tasks.\n   - **External Memory**: Access to external databases for vast information.\n\n### Actions:\n- Implement semantic search using Pinecone to enhance travel offerings.\n- Analyze customer feedback and competitor offerings to identify gaps and trends.\n- Develop marketing strategies leveraging storytelling, user-generated content, and nostalgia.\n- Personalize marketing messages and travel packages.\n- Address negative feedback by improving service quality.\n- Explore AI memory mechanisms to enhance information retrieval and application."
          },
          "metadata": {}
        }
      ]
    }
  ]
}