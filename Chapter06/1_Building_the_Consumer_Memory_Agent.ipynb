{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA2_SNjzA4Dc"
      },
      "source": [
        "# Consumer Memory Agent\n",
        "**Applying a multimodal thread of reasoning to customer service**     \n",
        "copyright 2025, Denis Rothman\n",
        "\n",
        "The goal of this notebook is to develop a consumer memory agent that applies neuroscience-inspired memory tagging to customer reviews, enabling the generation of personalized messages.\n",
        "\n",
        "**Table of Contents**\n",
        "\n",
        "1. **Setting up the environment**\n",
        "\n",
        "2. **The dataset:Trip advisor hotel reviews**\n",
        "\n",
        "3. **Agent Memory Functions**\n",
        "   - Querying Agent Memory\n",
        "   - Upserting Functions\n",
        "   - Memory Structure\n",
        "\n",
        "4. **Building the Agent's Memory Structure**\n",
        "    - Memory Hierarchy\n",
        "    - Visualizing Memory Categories\n",
        "\n",
        "5. **Strategic consumer agent memory**\n",
        "    - TripAdvisor Hotel Reviews Analysis\n",
        "    - Sentiment Analysis and Memory Tagging\n",
        "    - Creating Marketing Content\n",
        "    - Image and Customer Message Generation\n",
        "\n",
        "6. **Deploying the Agent in a CoT function**\n",
        "    - Combining Steps into a Unified Function\n",
        "    - Deployment in Marketing Analysis\n",
        "\n",
        "\n",
        "**Note**: *This notebook is for educational purposes only. It is not designed to be deployed into production.*\n",
        "\n",
        "This notebook uses OpenAI GPT Models. https://openai.com\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vub82Rjxa17a"
      },
      "source": [
        "# Setting up the environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8_G2ePO11rQ"
      },
      "source": [
        "## File downloading script\n",
        "\n",
        "grequests contains a script to download files from the repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4_26Hfdx2kX",
        "outputId": "c04bcd53-d2e1-40c7-a0cb-0c3bd80d7eee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1008  100  1008    0     0   2207      0 --:--:-- --:--:-- --:--:--  2210\n"
          ]
        }
      ],
      "source": [
        "#Private repository notes\n",
        "#1.This line will be deleted when the repository is made public and the following line will be uncommented\n",
        "#2.The private token will also be removed from grequests.py in the commmons directory of the repository\n",
        "!curl -L -H \"Authorization: Bearer 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\" https://raw.githubusercontent.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/master/commons/grequests.py --output grequests.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vzkCTNNChWAJ"
      },
      "outputs": [],
      "source": [
        "#!curl -L https://raw.githubusercontent.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/master/commons/grequests.py --output grequests.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmmBBZ7oa17b"
      },
      "source": [
        "## OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_PuE5rjhWAK",
        "outputId": "3fec63c1-2938-46ec-86f2-a270a1091397"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 'requirements01.py' successfully.\n",
            "Downloaded 'openai_setup.py' successfully.\n",
            "Downloaded 'reason.py' successfully.\n",
            "Downloaded 'machine_learning.py' successfully.\n"
          ]
        }
      ],
      "source": [
        "from grequests import download\n",
        "download(\"commons\",\"requirements01.py\")\n",
        "download(\"commons\",\"openai_setup.py\")\n",
        "download(\"commons\",\"reason.py\")\n",
        "download(\"commons\",\"machine_learning.py\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kNLfjTfAnFR"
      },
      "source": [
        "### Installing OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7i8j5vnpatH",
        "outputId": "56edae4e-6efa-410b-8e23-a8c160f37c7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uninstalling 'openai'...\n",
            "Installing 'openai' version 1.57.1...\n"
          ]
        }
      ],
      "source": [
        "# Run the setup script to install and import dependencies\n",
        "%run requirements01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O03SZzGGAreV"
      },
      "source": [
        "#### Initializing the OpenAI API key\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDn09vPbAXPT"
      },
      "outputs": [],
      "source": [
        "google_secrets=True #activates Google secrets in Google Colab\n",
        "if google_secrets==True:\n",
        "  import openai_setup\n",
        "  openai_setup.initialize_openai_api()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3398f_cetsD"
      },
      "outputs": [],
      "source": [
        "if google_secrets==False: # Uncomment the code and choose any method you wish to initialize the API_KEY\n",
        "  import os\n",
        "  #API_KEY=[YOUR API_KEY]\n",
        "  #os.environ['OPENAI_API_KEY'] = API_KEY\n",
        "  #openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "  #print(\"OpenAI API key initialized successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NL93eSL-mLi"
      },
      "source": [
        "#### Importing the API call function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lMhv09G0kzr"
      },
      "outputs": [],
      "source": [
        "# Import the function from the custom OpenAI API file\n",
        "import os\n",
        "import reason\n",
        "from reason import make_openai_api_call"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGpMI-5iLFMm"
      },
      "source": [
        "## Installing gtts\n",
        "\n",
        "gTTS (Google Text-to-Speech) is a Python library and CLI tool that interfaces with Google Translate's text-to-speech API. It allows users to convert text into spoken words, supporting multiple languages and accents, and can save the output as MP3 files.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_XpDBL-cLHTT"
      },
      "outputs": [],
      "source": [
        "!pip install gTTS==2.5.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVLHE2xaBuL2"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "import numpy as np\n",
        "\n",
        "def text_to_speech(text):\n",
        "    # Convert text to speech and save as an MP3 file\n",
        "    tts = gTTS(text)\n",
        "    tts.save(\"response.mp3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWL8u0g8Em1m"
      },
      "source": [
        "## Machine learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edZKk7Q2FzVi"
      },
      "outputs": [],
      "source": [
        "# Import the function from the custom OpenAI API file\n",
        "import os\n",
        "import machine_learning\n",
        "from machine_learning import ml_agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeaIj1Y6GNva"
      },
      "source": [
        "## Web search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGVnBoLNF2EC"
      },
      "outputs": [],
      "source": [
        "download(\"commons\",\"web_search.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jL3Og0uYFPqo"
      },
      "outputs": [],
      "source": [
        "# Import the function from the custom OpenAI API file\n",
        "import os\n",
        "import web_search\n",
        "from web_search import search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHjBYt-f6S4d"
      },
      "source": [
        "## Chain of Thought(COT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SLXIJHF6kTQ"
      },
      "outputs": [],
      "source": [
        "# Import the function from the custom OpenAI API file\n",
        "import os\n",
        "import reason\n",
        "from reason import chain_of_thought_reasoning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QGI1D8FVrT6"
      },
      "source": [
        "## Installing Pinecone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3ufJsT54EHe"
      },
      "outputs": [],
      "source": [
        "download(\"commons\",\"requirements02.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Z2abuU9OkVFL"
      },
      "outputs": [],
      "source": [
        "# Run the setup script to install and import dependencies\n",
        "%run requirements02"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tum9Jd1odcNK"
      },
      "source": [
        "### Initializing the Pinecone API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eIyjdd25LjH"
      },
      "outputs": [],
      "source": [
        "download(\"commons\",\"pinecone_setup.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zPS_mgsdXKj"
      },
      "outputs": [],
      "source": [
        "if google_secrets==True:\n",
        "  import pinecone_setup\n",
        "  pinecone_setup.initialize_pinecone_api()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-dJTlEn_FZZ"
      },
      "outputs": [],
      "source": [
        "if google_secrets==False: # Uncomment the code and choose any method you wish to initialize the Pinecone API key\n",
        "  import os\n",
        "  #PINECONE_API_KEY=[YOUR PINECONE_API_KEY]\n",
        "  #os.environ['PINECONE_API_KEY'] = PINECONE_API_KEY\n",
        "  #openai.api_key = os.getenv(\"PINECONE_API_KEY\")\n",
        "  #print(\"OpenAI API key initialized successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XswfiN5Z1OvT"
      },
      "source": [
        "##  The Pinecone index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKCvBbZPTIjH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "# Retrieve the API key from environment variables\n",
        "api_key = os.environ.get('PINECONE_API_KEY')\n",
        "if not api_key:\n",
        "    raise ValueError(\"PINECONE_API_KEY is not set in the environment!\")\n",
        "\n",
        "# Initialize the Pinecone client\n",
        "pc = Pinecone(api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P---PNLpXeQs"
      },
      "outputs": [],
      "source": [
        "from pinecone import ServerlessSpec\n",
        "\n",
        "index_name = 'genai-v1'\n",
        "cloud = os.environ.get('PINECONE_CLOUD') or 'aws'\n",
        "region = os.environ.get('PINECONE_REGION') or 'us-east-1'\n",
        "\n",
        "spec = ServerlessSpec(cloud=cloud, region=region)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jO7AYljM0gq1"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pinecone\n",
        "# check if index already exists (it shouldn't if this is first time)\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    # if does not exist, create index\n",
        "    pc.create_index(\n",
        "        index_name,\n",
        "        dimension=1536,  # dimension of the embedding model\n",
        "        metric='cosine',\n",
        "        spec=spec\n",
        "    )\n",
        "    # wait for index to be initialized\n",
        "    time.sleep(1)\n",
        "\n",
        "# connect to index\n",
        "index = pc.Index(index_name)\n",
        "# view index stats\n",
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iIIeZB7RUDZ"
      },
      "source": [
        "## Querying functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NS2HWdO76iQh"
      },
      "outputs": [],
      "source": [
        "def display_results(query_results):\n",
        "  for match in query_results['matches']:\n",
        "    print(f\"ID: {match['id']}, Score: {match['score']}\")\n",
        "    if 'metadata' in match and 'text' in match['metadata']:\n",
        "        text=match['metadata']['text']\n",
        "        #print(f\"Text: {match['metadata']['text']}\")\n",
        "        target_id = query_results['matches'][0]['id']  # Get the ID from the first match\n",
        "                #print(f\"Target ID: {target_id}\")\n",
        "    else:\n",
        "        print(\"No metadata available.\")\n",
        "  return text, target_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DT6wytGz5hTS"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "client = openai.OpenAI()\n",
        "embedding_model = \"text-embedding-3-small\"\n",
        "def get_embedding(text, model=embedding_model):\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    response = client.embeddings.create(input=[text], model=model)\n",
        "    embedding = response.data[0].embedding\n",
        "    return embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FxS2Q0nnZAq"
      },
      "outputs": [],
      "source": [
        "def get_query_results(query_text, namespace):\n",
        "    # Generate the query vector from the query text\n",
        "    query_vector = get_embedding(query_text)  # Replace with your method to generate embeddings\n",
        "\n",
        "    # Perform the query\n",
        "    query_results = index.query(\n",
        "        vector=query_vector,\n",
        "        namespace=namespace,\n",
        "        top_k=1,  # Adjust as needed\n",
        "        include_metadata=True\n",
        "    )\n",
        "    # Return the results\n",
        "    return query_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-k5GxQGZSjlY"
      },
      "outputs": [],
      "source": [
        "def query_vector_store(query_text, namespace):\n",
        "    print(\"Querying vector store...\")\n",
        "\n",
        "    # Retrieve query results\n",
        "    query_results = get_query_results(query_text, namespace)\n",
        "\n",
        "    # Process and display the results\n",
        "    print(\"Processed query results:\")\n",
        "    text, target_id = display_results(query_results)\n",
        "\n",
        "    return text, target_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "022ADwbe3WmV"
      },
      "source": [
        "# The dataset: Trip advisor hotel reviews\n",
        "\n",
        "https://www.kaggle.com/datasets/andrewmvd/trip-advisor-hotel-reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWG2zCZDGimF"
      },
      "source": [
        "Strategic Storytelling: Leveraging Memory in Marketing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBmqSgyQ5hIi"
      },
      "source": [
        "## Download and process data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqULBYA65SxH"
      },
      "outputs": [],
      "source": [
        "download(\"Chapter06\",\"tripadvisor_hotel_reviews.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvBGTZgb5q61"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Load the CSV file into a Pandas DataFrame\n",
        "dfta = pd.read_csv('/content/tripadvisor_hotel_reviews.csv')\n",
        "# display the DataFrame\n",
        "dfta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v027Jf0a6BPG"
      },
      "source": [
        "### Select index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keY1soDi6EZO"
      },
      "outputs": [],
      "source": [
        "index_number = 2  # Specify the index number\n",
        "\n",
        "try:\n",
        "    # Retrieve the row at the specified index\n",
        "    row = dfta.iloc[index_number]\n",
        "\n",
        "    # Extract the desired fields\n",
        "    review = row['Review']\n",
        "    rating = row['Rating']\n",
        "\n",
        "    # Display the results\n",
        "    print(f\"Review: {review}\")\n",
        "    print(f\"Rating: {rating}\")\n",
        "except IndexError:\n",
        "    print(f\"Error: Index {index_number} is out of bounds for the DataFrame.\")\n",
        "except KeyError as e:\n",
        "    print(f\"Error: Column '{e}' not found in the DataFrame.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAP6WVAJr2QF"
      },
      "source": [
        "### Input for the consumer memory agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2WuJNUij_6J"
      },
      "outputs": [],
      "source": [
        "input1=review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pqFSbGecoZ3"
      },
      "source": [
        "## The functions of the consumer memory agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA8xaVeCsHTi"
      },
      "source": [
        "## Prompts and messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZsjrrG9EMzr"
      },
      "outputs": [],
      "source": [
        "download(\"commons\",\"cot_messages_c6.py\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNEo5B1JAyUO"
      },
      "source": [
        "## Step 1 : Memory and sentiment analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmxJkvCe-4Bu"
      },
      "source": [
        "### The complex system message for step 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DG1fErLS67ey"
      },
      "outputs": [],
      "source": [
        "from cot_messages_c6 import system_message_s1\n",
        "#print(system_message_s1) # Print to verify"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running the analysis"
      ],
      "metadata": {
        "id": "yvM6TQXvz1ns"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbplKfEWhnJi"
      },
      "outputs": [],
      "source": [
        "# Step 1 : Memory and sentiment analysis\n",
        "mrole= system_message_s1\n",
        "user_text=review\n",
        "mcontent = \"You are a psychologist specialized in the memory and emotional analysis of content\"\n",
        "user_role = \"user\"\n",
        "retres=reason.make_openai_o1_call(user_text, mrole,mcontent,user_role)\n",
        "\n",
        "# Print the generated output (memory analysis)\n",
        "print(retres)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNBDCotShcL0"
      },
      "source": [
        "## Step 2: Extract scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EepkowkRmSMf"
      },
      "outputs": [],
      "source": [
        "def extract(tasks_response):\n",
        "  umessage = \"\"\"\n",
        "  1) Read the following text analysis that returns detailled memory tags for each part of the text\n",
        "  2) Then return the list of memory tags with absolutely no other text\n",
        "  3) Use no formatting, no hastages, no markdown. Just answer in plain text\n",
        "  4) Also provide the sentiment analysis score for each tag in this format(no brackets) : memory tag sentiment Score\n",
        "  \"\"\"\n",
        "  umessage+=retres\n",
        "  mrole = \"system\"\n",
        "  mcontent = \"You are a marketing expert specialized in the psychological analysis of content\"\n",
        "  user_role = \"user\"\n",
        "  task_response = reason.make_openai_api_call(umessage,mrole,mcontent,user_role)\n",
        "  return task_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Mdsl8HKa5zL"
      },
      "outputs": [],
      "source": [
        "# Step 2: Extract scores\n",
        "task_response=extract(retres)\n",
        "print(task_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d1GU66kPhIV"
      },
      "source": [
        "## Step 3: Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-WoQLq4h84t"
      },
      "outputs": [],
      "source": [
        "# Step 3 : Statistics\n",
        "import re\n",
        "\n",
        "# Input text\n",
        "text=task_response\n",
        "\n",
        "# Regular expression to extract sentiment scores\n",
        "pattern = r\"(\\d+\\.\\d+)\"\n",
        "scores = [float(match) for match in re.findall(pattern, text)]\n",
        "\n",
        "# Output the extracted scores\n",
        "print(\"Extracted sentiment scores:\", scores)\n",
        "\n",
        "# Optional: calculate the overall score and scaled rating\n",
        "if scores:\n",
        "    overall_score = sum(scores) / len(scores)\n",
        "    scaled_rating = overall_score * 5\n",
        "    print(\"Overall score (0–1):\", round(overall_score, 2))\n",
        "    print(\"Scaled rating (0–5):\", round(scaled_rating, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cv4gd6_pNMwJ"
      },
      "source": [
        "## Step 4: Content creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPDfsAHVznjr"
      },
      "source": [
        "### Messages for step 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VntKIU7Uznjt"
      },
      "outputs": [],
      "source": [
        "from cot_messages_c6 import umessage4\n",
        "#print(umessage4) # Print to verify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veWFoC3zznjt"
      },
      "outputs": [],
      "source": [
        "from cot_messages_c6 import utarget4\n",
        "#print(utarget4) # Print to verify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpYibVQrznju"
      },
      "outputs": [],
      "source": [
        "from cot_messages_c6 import utarget4b\n",
        "# Print to verify\n",
        "#print(utarget4b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh5HWLETlotj"
      },
      "source": [
        "### The content creation call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EsTGiOBNS4g"
      },
      "outputs": [],
      "source": [
        "#Step 4: Creating content\n",
        "if scaled_rating >= 3:\n",
        "  umessage = umessage4\n",
        "  umessage+=task_response + utarget4\n",
        "\n",
        "if scaled_rating <3:\n",
        "  umessage = umessage4\n",
        "  umessage+=task_response + utarget4b\n",
        "\n",
        "mrole = \"system\"\n",
        "mcontent = \"You are a marketing expert specialized in the psychological analysis of content\"\n",
        "user_role = \"user\"\n",
        "pre_creation_response = reason.make_openai_api_call(umessage,mrole,mcontent,user_role)\n",
        "print(pre_creation_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUaUENv3taIZ"
      },
      "outputs": [],
      "source": [
        "umessage=\"Clean and simplify the following text for use as a DALL-E prompt. Focus on converting the detailed analysis into a concise visual description suitable for generating an engaging promotional image\" + pre_creation_response\n",
        "mrole = \"system\"\n",
        "mcontent = \"You are a marketing expert specialized in the psychological analysis of content\"\n",
        "user_role = \"user\"\n",
        "creation_response = reason.make_openai_api_call(umessage,mrole,mcontent,user_role)\n",
        "print(creation_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAC82qrqQoTR"
      },
      "source": [
        "## Step 5 Image creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkXzWbzhQtmI"
      },
      "outputs": [],
      "source": [
        "# Step 5: Creating an image\n",
        "import requests\n",
        "prompt=creation_response\n",
        "image_url = reason.generate_image(prompt)\n",
        "save_path = \"c_image.png\"\n",
        "image_data = requests.get(image_url).content\n",
        "with open(save_path, \"wb\") as file:\n",
        "  file.write(image_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_B9lwFRURvA"
      },
      "source": [
        "## Step 6 Message creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxK0sbXVPi5F"
      },
      "outputs": [],
      "source": [
        "# Step 6: Creating a customer message\n",
        "\n",
        "if creation_response != \"\":\n",
        "  umessage = \"\"\"\n",
        "  1) Read the following text carefully\n",
        "  2) Then sum it up in a paragraphs without numbering the lines\n",
        "  3) They output should be a text to send to a customer\n",
        "  \"\"\"\n",
        "  umessage+=creation_response\n",
        "  mrole = \"system\"\n",
        "  mcontent = \"You are an expert in summarization for texts to send to a customer\"\n",
        "  user_role = \"user\"\n",
        "  process_response = reason.make_openai_api_call(umessage,mrole,mcontent,user_role)\n",
        "  print(process_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display outputs"
      ],
      "metadata": {
        "id": "ZsK139jO4RbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import Image, display\n",
        "import textwrap\n",
        "# Set the desired width for each line\n",
        "line_width = 70\n",
        "# Wrap the text to the specified width\n",
        "wrapped_message = textwrap.fill(process_response, width=line_width)\n",
        "print(wrapped_message)\n",
        "\n",
        "# Define the image path\n",
        "image_path = \"/content/c_image.png\"\n",
        "\n",
        "# Check if the image file exists\n",
        "if os.path.exists(image_path):\n",
        "    # Display the image\n",
        "    display(Image(filename=image_path))\n",
        "else:\n",
        "    print(f\"Image file {image_path} not found.\")"
      ],
      "metadata": {
        "id": "hhA1aqDj4BnG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "JBmqSgyQ5hIi"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyPpwzWgKEyBy7g5pBwOgyKD"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}